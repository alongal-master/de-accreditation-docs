{
  "title": "llm-pt",
  "description": "",
  "modifiedAt": "",
  "createdAt": "2026-01-12",
  "isPublished": false,
  "trackType": "Programming",
  "version": 1,
  "terms": [
    {
      "courses": [
        {
          "title": "llm-pt",
          "description": "",
          "displayId": "",
          "credits": 0,
          "units": [
            {
              "title": "Foundations of LLMs",
              "lessons": [
                {
                  "title": "AI vs Generative AI",
                  "masteryOutcomes": [
                    "Distinguish AI, Generative AI, NLP, and LLMs using concrete examples",
                    "Identify tasks suited for generative models vs traditional software",
                    "Use correct terminology when describing GenAI systems"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "From ML to LLMs",
                  "masteryOutcomes": [
                    "Describe the progression from rule-based systems ‚Üí machine learning ‚Üí deep learning ‚Üí LLMs",
                    "Explain at a high level why neural networks enabled modern language models",
                    "Identify what changed with transformers compared to earlier approaches"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: AI and Generative AI Scenarios",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Distinguish between AI, Generative AI, NLP, and LLMs and match each to concrete real-world tasks.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: From Rules to LLMs Timeline",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Explain the progression from rule-based systems to ML, deep learning, and LLMs and identify what changed at each step, especially with transformers.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "What Makes an LLM",
                  "masteryOutcomes": [
                    "Define a Large Language Model in practical terms",
                    "Explain the difference between training and inference at a high level",
                    "Describe what information an LLM can and cannot use at runtime"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Tokens, Context, and Prediction",
                  "masteryOutcomes": [
                    "Define tokens, tokenization, and context window",
                    "Explain next-token prediction as the core LLM mechanism",
                    "Connect context limits and tokenization to model behavior and limitations"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Training vs Inference and Model Capabilities",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Differentiate training from inference and identify what information an LLM can and cannot access at runtime.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Tokens and Context Window Puzzles",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Apply concepts of tokens, tokenization, context window, and next-token prediction to reason about model behavior and limitations.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Common Models in Practice",
                  "masteryOutcomes": [
                    "Identify widely used LLM products (e.g. ChatGPT, Gemini, Claude, Copilot)",
                    "Distinguish model, product, and interface",
                    "Match common models to typical tasks (chatting, coding help, summarization, analysis)"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "How We Use LLMs",
                  "masteryOutcomes": [
                    "Identify common interfaces to LLMs (chat websites vs APIs)",
                    "Compare interactive chat usage with programmatic API usage",
                    "Explain how product design shapes model interaction"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Model, Product, and Interface Matching",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Identify common LLM products and correctly distinguish between the underlying model, the product built around it, and the user interface.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Chat vs API Usage Stories",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Compare interactive chat usage with programmatic API usage and explain how product design shapes how users interact with LLMs.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Stateless by Default",
                  "masteryOutcomes": [
                    "Define statelessness in the context of LLMs",
                    "Explain why LLMs do not remember past interactions by default",
                    "Describe how conversation history is simulated using context"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Determinism and Reproducibility",
                  "masteryOutcomes": [
                    "Explain why LLM outputs are not fully deterministic",
                    "Identify factors that affect reproducibility (prompt, parameters, context)",
                    "Describe scenarios where reproducibility is critical"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Stateless Conversations and Simulated Memory",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Describe statelessness in LLMs and explain how conversation history is simulated using context rather than true memory.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Reproducibility and Parameters Case Study",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Identify why LLM outputs are not fully deterministic and list the main factors affecting reproducibility in different scenarios.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                }
              ]
            },
            {
              "title": "Prompt Design Foundations",
              "lessons": [
                {
                  "title": "Prompts as Interfaces",
                  "masteryOutcomes": [
                    "Define a prompt as an interface between humans and LLMs",
                    "Explain how ambiguity affects model behavior",
                    "Identify why prompts must be designed, not improvised"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Prompt Anatomy",
                  "masteryOutcomes": [
                    "Break a prompt into role, instructions, context, and output",
                    "Identify missing or conflicting prompt components",
                    "Refactor poorly structured prompts into clearer ones"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Prompt interfaces in real scenarios",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Apply the concept of prompts as interfaces by diagnosing ambiguity and design quality in real-life prompt examples.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Prompt anatomy dissection",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Decompose prompts into role, instructions, context, and output, then refactor them to resolve missing or conflicting components.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "RTCO Framework",
                  "masteryOutcomes": [
                    "Define Role, Task, Context, Output precisely",
                    "Apply RTCO to structure prompts",
                    "Evaluate prompts using RTCO as a checklist"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Writing Clear Tasks",
                  "masteryOutcomes": [
                    "Write task instructions that are specific and testable",
                    "Identify vague verbs and unclear goals",
                    "Rewrite tasks to reduce ambiguity"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: RTCO checklist for study assistant prompts",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Use the RTCO framework to design and evaluate prompts for an educational Q&A assistant. Output: A small library of 4-6 RTCO-structured prompts for a study assistant, each with an accompanying RTCO checklist evaluation.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Task clarity in productivity tools",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Rewrite vague instructions into specific, testable tasks for a productivity and personal tools assistant. Output: A before/after collection of task instructions showing the original vague version and the clarified, testable version for each case.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Defining Outputs",
                  "masteryOutcomes": [
                    "Specify output format and constraints explicitly",
                    "Define what counts as valid vs invalid output",
                    "Reduce model confusion through output definition"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Zero-shot and Few-shot Prompting",
                  "masteryOutcomes": [
                    "Define zero-shot prompting and few-shot prompting",
                    "Select examples that guide model behavior",
                    "Compare zero-shot and few-shot outputs"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Output definitions for budgeting summaries",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Define explicit output formats and constraints for a finance and budgeting summary assistant and validate them against example outputs. Output: A mini ‚Äúoutput spec sheet‚Äù plus 3-5 example prompts and model responses annotated as valid or invalid according to the spec.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Zero-shot vs few-shot quiz helper",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Compare zero-shot and few-shot prompting strategies for an education quiz helper and analyze how examples change the model‚Äôs behavior. Output: A short experiment log containing pairs of zero-shot and few-shot prompts, their outputs, and brief written comparisons.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Why Models Hallucinate",
                  "masteryOutcomes": [
                    "Define hallucination in practical terms",
                    "Identify prompt-related causes of hallucinations",
                    "Distinguish hallucinations from formatting or parsing errors",
                    "Learn how to reduce the change of hallucinations through prompting"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Prompt Iteration",
                  "masteryOutcomes": [
                    "Analyze model outputs for failure modes",
                    "Modify prompts based on observed issues",
                    "Track improvements across iterations"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Hallucination detective for travel planner",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Identify and categorize hallucinations in a travel and routing assistant‚Äôs responses, then redesign prompts to reduce those hallucinations. Output: A table of travel-planning responses labeled with hallucination types and improved prompt versions aimed at mitigating each issue.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Prompt iteration for content organizer",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Iteratively refine prompts for a content organization and tagging assistant by analyzing failure modes and tracking improvements across versions. Output: A versioned prompt log (v1, v2, v3, ‚Ä¶) showing each prompt, its output issues, and the specific changes made to improve the next iteration.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                }
              ]
            },
            {
              "title": "Message Design & Control",
              "lessons": [
                {
                  "title": "First API Call",
                  "masteryOutcomes": [
                    "Structure a basic LLM API request",
                    "Send input and receive a response",
                    "Inspect raw model outputs"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Message Roles Explained",
                  "masteryOutcomes": [
                    "Define system and user messages",
                    "Explain how message roles affect behavior",
                    "Identify misuse of message roles"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: First API call playground",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: You will be able to construct and send a minimal LLM API request, then inspect and interpret the raw response for a simple productivity assistant scenario. Output: A small script that sends a prompt to the model and prints the full raw response, including role, content, and any metadata.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Message roles analyzer",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: You will be able to design and compare different combinations of system and user messages, and identify when message roles are used correctly or misused in a media/content assistant context. Output: A script that sends several request variants with different message-role setups and prints a side-by-side comparison of how the model‚Äôs behavior changes.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "System Messages in Practice",
                  "masteryOutcomes": [
                    "Write system messages defining role and behavior",
                    "Create reusable system prompts",
                    "Separate behavior rules from task logic"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "User Messages in Practice",
                  "masteryOutcomes": [
                    "Write user messages containing task and context",
                    "Inject dynamic input safely",
                    "Combine system and user messages effectively"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: System prompt library",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: You will be able to write clear, reusable system messages that define behavior separately from task logic for an education quiz helper. Output: A small module or script containing a ‚Äúsystem prompt library‚Äù plus a demo call that shows how swapping system prompts changes the model‚Äôs responses.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Task-focused user prompts",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: You will be able to craft user messages that safely inject dynamic input and context, and combine them effectively with system prompts for a budgeting/finance helper. Output: A script that takes user input (e.g., recent expenses) and sends a combined system+user message to the model, printing back tailored budgeting suggestions.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Temperature and Output Control",
                  "masteryOutcomes": [
                    "Define temperature as a behavior control parameter",
                    "Explain how temperature affects randomness",
                    "Choose temperature settings for different tasks"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Structured Outputs",
                  "masteryOutcomes": [
                    "Define structured outputs and schemas",
                    "Instruct models to return valid JSON",
                    "Identify common structured-output failures"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Temperature tuning for creativity",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: You will be able to adjust temperature and related parameters to balance creativity and reliability for a content-idea generator. Output: A script that calls the model multiple times with different temperature settings and prints a comparative table of generated content ideas for each setting.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: JSON response schema",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: You will be able to instruct the model to produce strictly structured JSON following a defined schema and recognize common failure modes in a habit-tracking scenario. Output: A script that sends a schema-aware prompt and prints the model‚Äôs JSON response for a daily habit log, highlighting whether it matches the expected structure.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Parsing and Validation",
                  "masteryOutcomes": [
                    "Parse structured responses in Python",
                    "Detect invalid or malformed outputs",
                    "Decide when to retry or fail gracefully"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Prompt Templates in Code",
                  "masteryOutcomes": [
                    "Store prompt templates as variables or functions",
                    "Inject runtime data into templates",
                    "Maintain readability and reuse"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Response parsing and validation",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: You will be able to parse JSON-like model outputs in Python, validate them against expectations, and decide when to retry or fail for a simple task-planning tool. Output: A script that calls the model for a task list, attempts to parse and validate the JSON, and either prints the cleaned task list or a clear error/retry message.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Prompt templates in code",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: You will be able to create and reuse prompt templates in code, injecting runtime data cleanly while keeping prompts readable for a travel-planning helper. Output: A script that defines prompt templates as variables or functions, fills them with user-provided trip details, and prints the model‚Äôs structured travel plan response.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                }
              ]
            },
            {
              "title": "Using GenAI in code",
              "lessons": [
                {
                  "title": "From Prompts to Systems",
                  "masteryOutcomes": [
                    "Distinguish prompts from GenAI systems",
                    "Identify system components beyond a single call",
                    "Explain why systems fail differently than prompts"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Single-Step vs Multi-Step Flows",
                  "masteryOutcomes": [
                    "Compare single-step and multi-step designs",
                    "Identify tasks that require decomposition",
                    "Explain complexity vs reliability tradeoffs"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Prompt vs System Scenarios",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Distinguish between single prompts and full GenAI systems by analyzing short real-world scenarios and identifying system components beyond a single call.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Single-Step vs Multi-Step Decomposition",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Decide when to use single-step vs multi-step flows by decomposing tasks and assessing complexity vs reliability tradeoffs.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Designing Prompt Pipelines",
                  "masteryOutcomes": [
                    "Design simple multi-step prompt pipelines",
                    "Define inputs and outputs between steps",
                    "Identify failure points in pipelines"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "What Is an Agent",
                  "masteryOutcomes": [
                    "Define an agent using role and decision logic",
                    "Distinguish agents from prompt chains",
                    "Identify agent responsibilities"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Content Review Pipeline Design",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Design a simple multi-step prompt pipeline for reviewing short articles, defining clear inputs/outputs between steps and identifying potential failure points. Output: A written pipeline specification with 3-5 steps, including a table of step inputs/outputs and an annotated list of where and how the pipeline might fail.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Study Assistant Agent Specification",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Define an agent for an education-themed study assistant by specifying its role, decision logic, and responsibilities compared to a simple prompt chain. Output: A concise agent spec document including role description, decision rules (when to summarize, quiz, or explain), and a comparison table against a non-agent prompt pipeline.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Agent Control Flow",
                  "masteryOutcomes": [
                    "Define decision rules for agents",
                    "Explain how agents choose next actions",
                    "Prevent unnecessary or repeated steps"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Tools and Tool Calling",
                  "masteryOutcomes": [
                    "Define tools as external functions",
                    "Design simple tool interfaces",
                    "Decide when an agent should call a tool"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Health Habit Coach Agent Flow - Part 1",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Design the control flow for a health habit coach agent, defining decision rules that prevent unnecessary or repeated steps. Output: A flowchart or step-by-step decision tree showing how the agent chooses its next action (ask clarification, suggest habit, adjust plan, or stop) for different user inputs.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Health Habit Coach Agent Tools - Part 2",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Define and integrate simple tools for the health habit coach agent, deciding when the agent should call each tool versus reasoning internally. Output: A tool catalog (name, purpose, inputs/outputs) plus annotated example interaction traces where the agent chooses whether to call tools like \"HabitLibraryLookup\" or \"ScheduleGenerator.\"",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Observability and Tracing",
                  "masteryOutcomes": [
                    "Define tracing and observability",
                    "Identify what should be logged",
                    "Explain how traces support debugging"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Debugging with Traces",
                  "masteryOutcomes": [
                    "Inspect prompt-response flows",
                    "Identify causes of incorrect outputs",
                    "Use traces to guide improvements"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Bug Hunt in a Travel Recommendation Trace",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Use observability and tracing concepts to inspect a logged travel recommendation flow, identify what should be logged, and locate causes of incorrect suggestions. Output: An analyzed trace document with highlighted log elements, notes on missing or weak logging, and a list of specific points where the system behavior went wrong.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Trace-Guided Improvements for a Q&A Bot",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Apply debugging with traces to propose concrete prompt or flow changes that fix issues in a Q&A bot‚Äôs responses. Output: A before/after comparison where each traced failure is linked to a proposed change (prompt tweak, additional step, or logging addition) and a short explanation of how the trace guided that improvement.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                }
              ]
            }
          ],
          "label": "",
          "teachingInstructions": "",
          "durationInWeeks": 4,
          "isPublished": false
        }
      ]
    }
  ]
}