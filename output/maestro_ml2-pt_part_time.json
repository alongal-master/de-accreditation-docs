{
  "title": "ml2-pt",
  "description": "",
  "modifiedAt": "",
  "createdAt": "2026-01-11",
  "isPublished": false,
  "trackType": "Programming",
  "version": 1,
  "terms": [
    {
      "courses": [
        {
          "title": "ml2-pt",
          "description": "",
          "displayId": "",
          "credits": 0,
          "units": [
            {
              "title": "ML Thinking Basics",
              "lessons": [
                {
                  "title": "What ML Is (and Isn‚Äôt)",
                  "masteryOutcomes": [
                    "Understand machine learning in contrast to rule-based systems",
                    "Identify problems that are appropriate for ML",
                    "Distinguish ML from traditional programming logic"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "ML Task Types",
                  "masteryOutcomes": [
                    "Identify the main machine learning task types: classification, regression, and clustering",
                    "Understand how these task types relate to supervised learning (classification, regression) and unsupervised learning (clustering)",
                    "Match real-world problems to the correct ML task and learning type (supervised vs. unsupervised)",
                    "Understand why choosing the correct task type is a critical step before selecting a model or evaluation metric"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: ML or Not ML?",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Distinguish clearly between problems suitable for rule-based solutions and those better suited for machine learning.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Task Type Detective",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Correctly identify whether real-world scenarios are classification, regression, or clustering, and whether they are supervised or unsupervised learning.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Data and Labels",
                  "masteryOutcomes": [
                    "Distinguish labeled vs unlabeled data",
                    "Identify input features and target variables",
                    "Understand how labels guide supervised learning"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Features as Signals",
                  "masteryOutcomes": [
                    "Define features as model inputs",
                    "Identify raw vs derived features",
                    "Understand why feature quality impacts model performance"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Finding Features and Labels",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Accurately identify input features and labels in different datasets and problem statements.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Feature Signals in a Recommendation App",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Differentiate between raw and derived features and explain how they might affect a simple movie recommendation scenario.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Training vs Prediction",
                  "masteryOutcomes": [
                    "Describe what happens during model training",
                    "Understand how trained models make predictions",
                    "Identify when a model is ‚Äúlearning‚Äù vs ‚Äúusing knowledge‚Äù"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Models as Functions",
                  "masteryOutcomes": [
                    "Describe a model as a function mapping inputs to outputs",
                    "Compare simple rule logic to learned decision boundaries",
                    "Understand why models generalize instead of memorizing"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Training vs Prediction Timeline",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Explain which steps in an ML story correspond to training and which correspond to prediction/use.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Models as Functions vs Rules",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Compare a rule-based decision process to a learned model by mapping both to the idea of ‚Äúinputs ‚Üí outputs.‚Äù",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "ML Workflow Overview",
                  "masteryOutcomes": [
                    "Outline the full ML workflow from data to prediction",
                    "Identify where data prep, training, and evaluation fit",
                    "Use correct ML vocabulary to describe each step"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Workflow Jigsaw - Cafe Loyalty Predictor",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Arrange and describe the main ML workflow steps for a cafe loyalty prediction story using correct vocabulary.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Name the Workflow Step",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Correctly match short descriptions of ML activities to their place in the overall ML workflow (data prep, training, evaluation, deployment, prediction).",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: From Raw Data to Predictions Map",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Construct a high-level map of an ML project, labeling where data, features, training, evaluation, and prediction occur.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                }
              ]
            },
            {
              "title": "From Data to Models",
              "lessons": [
                {
                  "title": "Loading Tabular Data",
                  "masteryOutcomes": [
                    "Load datasets using pandas",
                    "Inspect rows, columns, and data types",
                    "Identify feature columns and targets"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Train / Test Split",
                  "masteryOutcomes": [
                    "Explain why test data must be held out",
                    "Split data using scikit-learn",
                    "Describe how splits affect evaluation trustworthiness"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Cafe orders dataset",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Load a tabular dataset with pandas, inspect its structure (rows, columns, dtypes), and distinguish feature columns from the target. Output: A small script that loads a cafe orders CSV, prints basic info/summary, and clearly displays which columns are features and which is the target.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Movie ratings train test split",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Perform a train/test split on a movie ratings dataset and explain how different split ratios affect the trustworthiness of model evaluation. Output: A script that loads a movie ratings CSV, performs one or more train/test splits, and prints the resulting shapes and a short text explanation of the chosen split.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Handling Missing Values",
                  "masteryOutcomes": [
                    "Identify missing data in datasets",
                    "Apply simple imputation strategies",
                    "Explain tradeoffs of different approaches"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Encoding Categories",
                  "masteryOutcomes": [
                    "Identify categorical vs numeric features",
                    "Encode categorical variables for ML models",
                    "Explain why models require numeric inputs"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Health records missing values",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Detect and summarize missing values in a health records dataset and apply simple imputation strategies while discussing their tradeoffs. Output: A script that loads a health dataset, reports missingness per column, applies at least two imputation strategies, and prints before/after comparisons.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Music app category encoding",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Identify categorical features in a music app user dataset and encode them into numeric form suitable for ML models, explaining why this step is necessary. Output: A script that loads a music user behavior CSV, detects categorical columns, applies one or more encoders, and prints the transformed feature matrix with encoded categories.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Scaling Numeric Features",
                  "masteryOutcomes": [
                    "Explain feature scale and why it matters",
                    "Apply basic scaling techniques",
                    "Identify models sensitive to feature scale"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Pipelines: One Clean Flow",
                  "masteryOutcomes": [
                    "Build a preprocessing + model pipeline",
                    "Explain how pipelines prevent data leakage",
                    "Use pipelines to simplify ML code"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: House prices scaling",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Apply feature scaling to numeric columns in a housing prices dataset and compare how different scaling methods change feature distributions. Output: A script that loads a housing CSV, scales selected numeric features using at least two scalers, and prints/plots basic statistics before and after scaling.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Loan approval pipeline",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Build a preprocessing and model pipeline for a loan approval dataset and show how it simplifies code while reducing the risk of data leakage. Output: A script that defines a scikit-learn Pipeline combining preprocessing steps and a model, fits it on training data, and evaluates it on test data with a single fit/predict flow.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "First Complete Model",
                  "masteryOutcomes": [
                    "Train a simple supervised ML model end-to-end",
                    "Generate predictions on test data",
                    "Inspect and interpret model outputs"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Email spam classifier - Part 1",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Prepare text-based email data and train a first complete supervised model, generating predictions on a held-out test set. Output: A script that loads an email spam dataset, splits it, vectorizes the text, trains a classifier, and outputs spam/not-spam predictions for the test set.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Email spam classifier - Part 2",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Inspect and interpret the outputs of the spam classifier, including basic metrics and example predictions, to understand model behavior. Output: A script that computes evaluation metrics (e.g., accuracy, precision, recall), prints a confusion matrix, and displays a few example emails with their predicted and true labels.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Taxi fare prediction",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Train an end-to-end regression model to predict taxi fares, then generate and briefly interpret numeric predictions for new rides. Output: A script that loads a taxi rides dataset, trains a regression model, and prints predicted fares for a sample of test or new ride inputs alongside their actual values where available.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                }
              ]
            },
            {
              "title": "Core ML Models & Evaluation",
              "lessons": [
                {
                  "title": "First Supervised Model - Logistic Regression",
                  "masteryOutcomes": [
                    "Explain binary classification problems",
                    "Train a Logistic Regression model end-to-end",
                    "Introduce the idea of predicted probabilities vs. predicted classes",
                    "Motivate the need for model evaluation (why accuracy alone is not enough)"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Classification Metrics",
                  "masteryOutcomes": [
                    "Calculate and interpret accuracy, precision, recall, and F1-score",
                    "Read and interpret a confusion matrix",
                    "Re-evaluate the Logistic Regression model using different metrics",
                    "Discuss how metric choice depends on the problem context"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Email spam detector",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Train and evaluate a Logistic Regression model for binary classification using predicted probabilities and class labels on an email spam dataset. Output: A script that loads sample email features, trains a spam vs. not-spam model, and prints predicted probabilities and classes for new emails.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Medical test confusion matrix",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Compute and interpret accuracy, precision, recall, F1-score, and a confusion matrix for a Logistic Regression model in a medical test scenario, and explain why accuracy alone can be misleading. Output: A script that trains a disease classifier, prints its confusion matrix and classification metrics, and compares model performance under different decision thresholds.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Linear Regression",
                  "masteryOutcomes": [
                    "Explain numeric prediction tasks",
                    "Train a Linear Regression model",
                    "Interpret predictions vs. actual values",
                    "Introduce regression error intuitively (distance from the true value)"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Regression Metrics",
                  "masteryOutcomes": [
                    "Calculate MAE, MSE/RMSE, and R¬≤",
                    "Explain what each metric reveals about model errors",
                    "Compare regression models using appropriate metrics"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Apartment price predictor",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Build a Linear Regression model to predict apartment prices from features, and compare predicted vs. actual prices to understand regression error as distance from the true value. Output: A script that trains a price prediction model and prints a side-by-side table of actual vs. predicted prices with their errors.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: House price metrics dashboard",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Calculate MAE, MSE, RMSE, and R¬≤ for a Linear Regression model on house prices and use these metrics to compare two different models or feature sets. Output: A script that trains two regression models, computes all regression metrics for each, and prints a concise comparison report.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Tree-Based Models",
                  "masteryOutcomes": [
                    "Explain decision trees at a conceptual level",
                    "Train a tree-based classifier",
                    "Compare linear vs. non-linear models",
                    "Discuss strengths and limitations of tree-based approaches"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Ensembles",
                  "masteryOutcomes": [
                    "Introduce ensemble methods (Random Forest, Gradient Boosting) at a high level",
                    "Explain why ensembles are commonly used in practice",
                    "Build intuition for why combining models often improves performance"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Loan approval decision tree",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Train and visualize a decision tree classifier for loan approval, and compare its behavior and decision boundaries conceptually to a linear model. Output: A script that fits a decision tree to loan application data, exports a simple tree visualization or text representation, and prints example decisions for sample applicants.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Customer churn ensembles",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Train tree-based ensemble models (Random Forest and Gradient Boosting) for customer churn prediction and compare their performance and intuition to a single decision tree. Output: A script that trains a baseline decision tree, a Random Forest, and a Gradient Boosting model, then prints their evaluation metrics side by side.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Overfitting, Generalization & Validation",
                  "masteryOutcomes": [
                    "Identify signs of overfitting and underfitting",
                    "Compare train vs. test performance",
                    "Explain the bias-variance tradeoff",
                    "Introduce cross-validation conceptually",
                    "Compare single train/test split vs. multiple folds"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Model overfitting quiz",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Identify overfitting, underfitting, and good generalization by analyzing given learning curves, train/test scores, and scenario descriptions in a written quiz-style exercise. Output: A completed answer sheet where each scenario is labeled as overfitting, underfitting, or well-generalized, with brief justifications.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Train vs. test performance explorer",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Experiment with model complexity (e.g., tree depth or polynomial degree) and observe how train and test performance change to build intuition for the bias-variance tradeoff. Output: A script that trains models of varying complexity, records train/test scores, and prints a small table or simple text-based summary of how performance evolves.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Cross-validation comparison",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Apply k-fold cross-validation conceptually and in code to compare a single train/test split with multiple folds, and interpret the stability of performance across folds. Output: A script that evaluates a model using one train/test split and k-fold cross-validation, then prints the fold scores, their mean, and a comparison to the single-split score.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                }
              ]
            },
            {
              "title": "Hyperparameters & Unsupervised ML",
              "lessons": [
                {
                  "title": "Hyperparameters and Search",
                  "masteryOutcomes": [
                    "Define hyperparameters vs learned parameters",
                    "Use GridSearchCV or RandomizedSearchCV",
                    "Interpret tuning results responsibly"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Unsupervised Learning",
                  "masteryOutcomes": [
                    "Explain how unsupervised learning differs from supervised",
                    "Identify use cases without labels",
                    "Describe exploratory ML goals"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Hyperparameter tuning for a spam filter",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Apply GridSearchCV and RandomizedSearchCV to tune hyperparameters, compare results, and interpret them without overfitting your conclusions. Output: A script that trains a simple spam vs not-spam classifier, runs hyperparameter search, and prints the best parameters and validation scores in a readable summary.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Supervised vs unsupervised scenarios",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Distinguish between supervised and unsupervised learning by matching real-world problems to the correct approach and articulating exploratory goals when labels are missing.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "K-Means Clustering",
                  "masteryOutcomes": [
                    "Explain how K-Means groups data",
                    "Train a clustering model",
                    "Interpret clusters at a high level"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "Choosing Number of Clusters",
                  "masteryOutcomes": [
                    "Explain the role of k",
                    "Use simple heuristics to choose cluster count",
                    "Interpret clustering tradeoffs"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Customer segments with K-Means",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Train a K-Means clustering model on synthetic customer data and interpret clusters in terms of simple customer ‚Äúpersonas.‚Äù Output: A script that fits K-Means, assigns each customer to a cluster, and prints basic cluster summaries (e.g., average spending and visits per cluster).",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Choosing k for a music listener dataset",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Use elbow and silhouette-style heuristics to choose the number of clusters and explain tradeoffs between too few and too many clusters. Output: A script that trains K-Means for several k values, computes simple metrics, and prints/plots results to help pick a reasonable k.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "PCA for Visualization",
                  "masteryOutcomes": [
                    "Explain dimensionality reduction intuitively",
                    "Apply PCA to reduce features",
                    "Visualize high-dimensional data in 2D"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "ML Results in Context",
                  "masteryOutcomes": [
                    "Avoid over-interpreting unsupervised outputs",
                    "Explain limitations of clustering and PCA",
                    "Communicate results responsibly"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: PCA visualization of handwritten digits",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Apply PCA to reduce high-dimensional data to 2D and visualize how data points group in the reduced space. Output: A script that loads a digits dataset, performs PCA to 2 components, and produces a 2D scatter plot colored by digit label.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "üìö Theory Practice Lesson: Interpreting unsupervised results responsibly",
                  "masteryOutcomes": [],
                  "teachingInstructions": "Create a challenge-based lesson that is grounded in the material covered in the **current unit until this lesson, where the student demonstrates the knowledge they have learned in a fun and engaging way. Avoid coding in this lesson.\nThe lesson should include between eight and ten interactive and dynamic rounds between the student and the Maestro. \nThe challenge may include different types of questions or learning experiences, such as varied question formats, interactive tasks, MCQ, identification or matching questions, etc.\nYou are free to choose any structure or format that best supports an engaging challenge experience.\nDuring the challenge itself, there is no need to provide feedback or corrections, the focus should remain entirely on the challenge experience.\nAfter all challenge rounds are completed, provide a short summary that offers encouraging feedback, highlights areas for professional improvement and refinement, and points out the student's strengths as demonstrated through their responses during the challenge.\nEnsure the lesson remains aligned with the topics that were taught and is appropriate for the student's level. Don't code in this lesson.\nLesson goals: Critically evaluate clustering and PCA outputs by identifying over-interpretation risks and rewriting misleading statements into responsible conclusions.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "End-to-End ML Project",
                  "masteryOutcomes": [
                    "Define a clear ML problem",
                    "Prepare data, train a model, and evaluate it",
                    "Use a pipeline and proper metrics"
                  ],
                  "teachingInstructions": "",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: House price predictor - Part 1",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Frame a clear supervised ML problem, prepare a tabular dataset, and build a basic preprocessing and modeling pipeline. Output: A script that loads housing data, splits it, applies preprocessing (e.g., imputation and encoding), and fits a baseline regression model using a pipeline.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: House price predictor - Part 2",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Evaluate the end-to-end model with appropriate metrics, perform simple tuning, and summarize results in plain language. Output: A script that extends Part 1 to compute evaluation metrics (e.g., RMSE), optionally tune hyperparameters, and print a concise performance report.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                },
                {
                  "title": "‚öô Practice Lesson: Movie recommendation classifier",
                  "masteryOutcomes": [],
                  "teachingInstructions": "This is a coding challenge lesson. In this lesson, do not introduce new topics; it is about solving an exercise using previously learned concepts only.\nGuide the student step by step toward the solution without writing the full answer or final code for them.\nBreak the problem into small, manageable steps and ask the student to implement each step before moving on.\nWhen the student is stuck, give progressive hints instead of solutions.\nYou may provide example inputs/outputs, edge cases, and clarification to help the student reason about correctness.\nReview the student's work by pointing out what's correct and what needs improvement, then suggest the next step.\nExercise theme is to be chosen based on the lesson title.\nExercise goals and desired output: Design and implement a small end-to-end ML project that predicts whether a user will like a movie, including problem definition, data prep, modeling, and evaluation. Output: A script that takes user-movie feature data, trains a classifier, evaluates it with classification metrics, and prints predictions for a few example users.",
                  "requiredPlugins": [
                    "code-editor"
                  ]
                }
              ]
            }
          ],
          "label": "",
          "teachingInstructions": "",
          "durationInWeeks": 4,
          "isPublished": false
        }
      ]
    }
  ]
}