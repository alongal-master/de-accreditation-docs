#!/usr/bin/env python3
"""
Syllabus Generator for Four-Week Course

This script creates an Excel syllabus file from a list of lesson titles.
It organizes lessons into 4 weeks with 3-4 chapters each, generates learning goals,
and estimates completion times to total 30 hours per week.
"""

import argparse
import os
import sys
import json
import re
from typing import List, Dict, Tuple
import openai
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, Border, Side
from openpyxl.utils import get_column_letter
from dotenv import load_dotenv
from prompts import (
    get_lesson_parsing_prompt, 
    get_week_learning_goals_prompt, 
    get_chapter_info_prompt,
    get_practice_sessions_for_week_prompt,
    get_maestro_json_prompt
)
from xlsx_to_maestro import XLSXToMaestroConverter

# Parse --format argument early (before module-level conditionals)
# Default to "part_time", can be overridden via command line: --format full_time
output_course_format = "part_time"
if "--format" in sys.argv:
    try:
        format_idx = sys.argv.index("--format")
        if format_idx + 1 < len(sys.argv) and sys.argv[format_idx + 1] in ["part_time", "full_time"]:
            output_course_format = sys.argv[format_idx + 1]
    except (ValueError, IndexError):
        pass

# Parse --start-week argument early (before module-level conditionals)
# Default to 1, can be overridden via command line: --start-week 3
START_WEEK_NUM = 1
if "--start-week" in sys.argv:
    try:
        sw_idx = sys.argv.index("--start-week")
        if sw_idx + 1 < len(sys.argv):
            START_WEEK_NUM = int(sys.argv[sw_idx + 1])
    except (ValueError, IndexError):
        pass

# Export options
EXPORT_TO_LESSONS_JSON = True
EXPORT_TO_MAESTRO_JSON = True

# Maestro JSON unit structure control
# When True: Use original 4 units from input file (based on UNIT: headers)
# When False: Use weeks/chapters structure (units = weeks from XLSX)
USE_ORIGINAL_UNITS_IN_MAESTRO = False



# Course structure constants
NUM_OF_CHAPTERS_PER_WEEK = 5  # Days per week

# Full time 
if output_course_format == "full_time":
    NUM_OF_WEEKS = 4 # Full time
    NUM_LESSONS_PER_CHAPTER = 9 # Full time
else:
# Part time
    NUM_OF_WEEKS = 8 # Part time
    NUM_LESSONS_PER_CHAPTER = 4.5 # Part time

NUM_WEEKLY_REVIEW_PER_WEEK = 1
WEEKLY_REVIEW_TITLE = "Weekly Review"

# Learning Media types
LESSON_TYPE_LESSON = "Lesson"
LESSON_TYPE_EXERCISE = "Exercise"
LESSON_TYPE_ASSESSMENT = "Assessment"
LESSON_TYPE_SYNC = "Group Class"

# Custom weekly review day configuration
# Set to True to use custom weekly review days with manually defined items
USE_CUSTOM_WEEKLY_REVIEW_DAYS = True

# Set to True to use the same review day content for all weeks
# If True, DEFAULT_WEEKLY_REVIEW_DAY will be used for all weeks
USE_SAME_REVIEW_FOR_ALL_WEEKS = True

# Full time
if output_course_format == "full_time":
    DEFAULT_WEEKLY_REVIEW_DAY = [
        {'title': 'Weekly Review Prep Session', 'learning_outcomes': 'We\'ll review key concepts and prepare for the assessment', 'time_minutes': 90, 'type': LESSON_TYPE_LESSON},
        {'title': 'Prep Lesson', 'learning_outcomes': 'Prep lesson for the weekly review', 'time_minutes': 30, 'type': LESSON_TYPE_LESSON},
        {'title': 'Weekly Review Assessment', 'learning_outcomes': 'Our weekly assessment, where you will test your knowledge from the last week using practical questions and challenges', 'time_minutes': 240, 'type': LESSON_TYPE_ASSESSMENT}
    ]
# Part time
else:
    DEFAULT_WEEKLY_REVIEW_DAY = [
        {'title': 'Weekly Review Prep Session', 'learning_outcomes': 'We\'ll review key concepts and prepare for the assessment', 'time_minutes': 45, 'type': LESSON_TYPE_LESSON},
        {'title': 'Weekly Review Assessment', 'learning_outcomes': 'Our weekly assessment, where you will test your knowledge from the last week using practical questions and challenges', 'time_minutes': 135, 'type': LESSON_TYPE_ASSESSMENT}
    ]

# Chapter title and learning goals for custom weekly review days
# If not specified, will be generated by AI
DEFAULT_WEEKLY_REVIEW_CHAPTER_TITLE = "Weekly Review"
DEFAULT_WEEKLY_REVIEW_CHAPTER_GOALS = "Review key concepts learned during the week and complete the weekly assessment."


# Custom weekly review day content (used if USE_SAME_REVIEW_FOR_ALL_WEEKS is False)
# Dictionary mapping week number to a list of items for that week's review day
# Each item is a dict with: 'title', 'learning_outcomes', 'time_minutes', 'type' (optional, defaults to LESSON_TYPE_LESSON)
# If USE_CUSTOM_WEEKLY_REVIEW_DAYS is True, this replaces the automatic weekly review
CUSTOM_WEEKLY_REVIEW_DAYS = {
    # Example for week-specific reviews:
    # 1: [
    #     {'title': 'Week 1 Review Session', 'learning_outcomes': 'Review key concepts from week 1', 'time_minutes': 60, 'type': LESSON_TYPE_LESSON},
    #     {'title': 'Week 1 Assessment', 'learning_outcomes': 'Complete assessment for week 1', 'time_minutes': 90, 'type': LESSON_TYPE_ASSESSMENT},
    # ],
}

# Items to add at the start and end of each day
# Each item is a dict with: 'title', 'learning_outcomes', 'time_minutes', 'type' (optional, defaults to LESSON_TYPE_LESSON)
# Items are added in the order they appear in the list


# Full time
if output_course_format == "full_time":
    ITEMS_AT_START_OF_DAY = [
        {'title': 'Opening session and Q&A', 'learning_outcomes': 'Ask questions, clarify concepts, and engage with instructors and peers in real-time.', 'time_minutes': 60, 'type': LESSON_TYPE_SYNC}
    ]
    ITEMS_AT_END_OF_DAY = [
        {'title': 'Closing session', 'learning_outcomes': 'Wrap up the day togeher with your peers and ask final questions', 'time_minutes': 30, 'type': LESSON_TYPE_SYNC}
    ]
else:
# Part time
    ITEMS_AT_START_OF_DAY = [
        {'title': 'Opening session and Q&A', 'learning_outcomes': 'Ask questions, clarify concepts, and engage with instructors and peers in real-time.', 'time_minutes': 30, 'type': LESSON_TYPE_SYNC}
    ]
    ITEMS_AT_END_OF_DAY = [
        {'title': 'Closing session', 'learning_outcomes': 'Wrap up the day togeher with your peers and ask final questions', 'time_minutes': 15, 'type': LESSON_TYPE_SYNC}
    ]


# Base time estimates (in minutes) for different lesson types
BASE_TIME_ESTIMATES = {
    "practice": 30,
    "weekly review": 240,
    "final assessment": 120,
    "sync session": 90,
    "default": 30
}

def strip_leading_number(title: str) -> str:
    """Strip leading numbers like '4. ' or '12. ' from title."""
    if not title:
        return title
    # Match patterns like "4. ", "12. ", "4) ", "4 - ", "4: " at the start
    cleaned = re.sub(r'^\d+[\.\)\-:\s]+\s*', '', title)
    return cleaned if cleaned else title

def strip_unit_prefix(unit_name: str) -> str:
    """Strip 'Unit X â€”' or 'Unit X -' prefix from unit name."""
    if not unit_name:
        return unit_name
    # Match patterns like "Unit 4 â€” ", "Unit 4 - ", "Unit 4: ", "Unit 4. " at the start
    # Also handles em dash (â€”), en dash (â€“), and regular hyphen (-)
    cleaned = re.sub(r'^Unit\s+\d+\s*[â€”â€“\-:\.]\s*', '', unit_name, flags=re.IGNORECASE)
    return cleaned if cleaned else unit_name

def normalize_dashes(text: str) -> str:
    """Replace em dashes (â€”), en dashes (â€“), and other dash variants with regular hyphens (-)."""
    if not text:
        return text
    # Replace em dash (â€”), en dash (â€“), and other unicode dashes with regular hyphen
    return re.sub(r'[â€”â€“âˆ’â€â€‘â€’â€•]', '-', text)

# AI Model
#DEFAULT_MODEL = "gpt-4-turbo"
#DEFAULT_MODEL = "gpt-4o-mini"
DEFAULT_MODEL = "gpt-5.1"

# Pricing per 1M tokens (as of 2024, update as needed)
MODEL_PRICING = {
    "gpt-5.1": {"input": 2.50, "output": 10.00},  # Update with actual pricing when available
    "gpt-4o": {"input": 2.50, "output": 10.00},
    "gpt-4o-mini": {"input": 0.15, "output": 0.60},
    "gpt-4-turbo": {"input": 10.00, "output": 30.00},
    "gpt-4": {"input": 30.00, "output": 60.00},
    "gpt-3.5-turbo": {"input": 0.50, "output": 1.50},
}

# Load environment variables
load_dotenv()

class SyllabusGenerator:
    def __init__(self, api_key: str, log_file: str = "openai_log.txt", model: str = DEFAULT_MODEL):
        """Initialize the syllabus generator with OpenAI API key."""
        self.api_key = api_key
        self.workbook = Workbook()
        self.worksheet = self.workbook.active
        self.worksheet.title = "Course Syllabus"
        self.log_file = log_file
        self.model = model
        self._init_log_file()
    
    def _init_log_file(self):
        """Initialize the log file with header."""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("OpenAI API Log - Syllabus Generator\n")
            f.write("=" * 80 + "\n")
            f.write(f"Started at: {self._get_timestamp()}\n")
            f.write(f"Model: {self.model}\n")
            f.write("=" * 80 + "\n\n")
    
    def _get_timestamp(self):
        """Get current timestamp for logging."""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def _log_api_call(self, prompt: str, response: str, call_type: str):
        """Log API call details to file."""
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(f"[{self._get_timestamp()}] {call_type}\n")
            f.write("-" * 60 + "\n")
            f.write("PROMPT:\n")
            f.write(prompt)
            f.write("\n\n")
            f.write("RESPONSE:\n")
            f.write(response)
            f.write("\n\n")
            f.write("=" * 80 + "\n\n")
    
    def _get_openai_client(self):
        """Get OpenAI client."""
        return openai.OpenAI(api_key=self.api_key)
    
    def _get_max_tokens_param(self, max_tokens_value: int) -> dict:
        """Get max_completion_tokens parameter for GPT-5 models."""
        return {"max_completion_tokens": max_tokens_value}
    
    def _calculate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """Calculate the cost of an API call based on token usage."""
        if self.model not in MODEL_PRICING:
            print(f"Warning: Pricing not available for model {self.model}")
            return 0.0
        
        pricing = MODEL_PRICING[self.model]
        input_cost = (input_tokens / 1_000_000) * pricing["input"]
        output_cost = (output_tokens / 1_000_000) * pricing["output"]
        total_cost = input_cost + output_cost
        return total_cost
    
    def read_lessons_from_file(self, file_path: str) -> List[Dict[str, str]]:
        """Read and parse lesson titles and learning outcomes from a text file using AI."""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            if not content:
                print("Error: File is empty.")
                sys.exit(1)
            
            # Use AI to parse the content into structured lesson data
            return self._parse_lessons_with_ai(content)
            
        except FileNotFoundError:
            print(f"Error: File '{file_path}' not found.")
            sys.exit(1)
        except Exception as e:
            print(f"Error reading file: {e}")
            sys.exit(1)
    
    def _parse_lessons_with_ai(self, content: str) -> List[Dict[str, str]]:
        """Use AI to parse free text lessons and learning outcomes into structured data."""
        prompt = get_lesson_parsing_prompt(content)
        
        try:
            client = self._get_openai_client()
            print("Parsing lessons with AI (streaming)...")
            
            # Use streaming for chunked responses
            stream = client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                **self._get_max_tokens_param(4000),
                temperature=0.1,
                stream=True
            )
            
            # Collect chunks and track usage
            ai_content = ""
            usage_data = None
            for chunk in stream:
                # Skip chunks without choices
                if not chunk.choices or len(chunk.choices) == 0:
                    continue
                    
                if chunk.choices[0].delta.content is not None:
                    content_chunk = chunk.choices[0].delta.content
                    ai_content += content_chunk
                    # Show progress
                    if len(ai_content) % 100 == 0:
                        print(".", end="", flush=True)
                # Capture usage data from the final chunk
                if hasattr(chunk, 'usage') and chunk.usage is not None:
                    usage_data = chunk.usage
            
            print()  # New line after progress dots
            
            # Display cost information
            if usage_data:
                cost = self._calculate_cost(usage_data.prompt_tokens, usage_data.completion_tokens)
                print(f"ðŸ“Š Tokens: {usage_data.prompt_tokens:,} in + {usage_data.completion_tokens:,} out = {usage_data.total_tokens:,} total | ðŸ’° ${cost:.4f}")
            
            # Log the API call
            self._log_api_call(prompt, ai_content, "LESSON PARSING (STREAMED)")
            
            lessons = []
            
            # Parse the structured response
            lines = ai_content.split('\n')
            current_lesson = {}
            current_unit = "Default Unit"  # Track current unit name
            collecting_outcomes = False
            outcomes_lines = []
            
            for line in lines:
                line = line.strip()
                if line.startswith('UNIT:'):
                    # Update current unit name
                    unit_name = line[5:].strip()
                    if unit_name:
                        # Strip "Unit X â€”" prefix and normalize dashes
                        current_unit = normalize_dashes(strip_unit_prefix(unit_name))
                elif line.startswith('TITLE:'):
                    # Save previous lesson if exists
                    if current_lesson:
                        # Join any collected outcome lines with semicolon
                        if outcomes_lines:
                            current_lesson['learning_outcomes'] = normalize_dashes('; '.join(outcomes_lines))
                        lessons.append(current_lesson)
                    # Strip leading numbers from title and normalize dashes
                    title = normalize_dashes(strip_leading_number(line[6:].strip()))
                    current_lesson = {'title': title, 'learning_outcomes': '', 'original_unit': current_unit}
                    collecting_outcomes = False
                    outcomes_lines = []
                elif line.startswith('OUTCOMES:'):
                    if current_lesson:
                        outcomes_text = line[9:].strip()
                        if outcomes_text:
                            outcomes_lines.append(outcomes_text)
                        collecting_outcomes = True
                elif collecting_outcomes and line and not line.startswith('TITLE:') and not line.startswith('UNIT:'):
                    # Collect additional outcome lines until next TITLE or UNIT
                    outcomes_lines.append(line)
            
            # Add the last lesson
            if current_lesson and current_lesson.get('title'):
                if outcomes_lines:
                    current_lesson['learning_outcomes'] = normalize_dashes('; '.join(outcomes_lines))
                lessons.append(current_lesson)
            
            if not lessons:
                raise ValueError("No lessons found in AI response")
            
            print(f"Successfully parsed {len(lessons)} lessons with AI")
            return lessons
            
        except Exception as e:
            print(f"Error parsing lessons with AI: {e}")
            raise RuntimeError(f"Failed to parse lessons with AI: {e}")
    
    
    def distribute_lessons(self, lessons: List[Dict[str, str]]) -> Dict[int, List[List[Dict[str, str]]]]:
        """
        Distribute lessons evenly across all weeks and chapters.
        Each chapter should have a clear topic.
        Lessons are distributed evenly without controlling per-day count.
        """
        total_lessons = len(lessons)
        lessons_per_week = total_lessons // NUM_OF_WEEKS
        remainder = total_lessons % NUM_OF_WEEKS
        
        distribution = {}
        lesson_index = 0
        
        for week in range(START_WEEK_NUM, START_WEEK_NUM + NUM_OF_WEEKS):
            # Distribute remainder lessons to first few weeks
            week_lesson_count = lessons_per_week + (1 if week <= remainder else 0)
            
            lessons_per_chapter = week_lesson_count // NUM_OF_CHAPTERS_PER_WEEK
            chapter_remainder = week_lesson_count % NUM_OF_CHAPTERS_PER_WEEK
            
            week_chapters = []
            for chapter in range(NUM_OF_CHAPTERS_PER_WEEK):
                # Distribute remainder lessons to first few chapters
                chapter_lesson_count = lessons_per_chapter + (1 if chapter < chapter_remainder else 0)
                
                chapter_lessons = lessons[lesson_index:lesson_index + chapter_lesson_count]
                week_chapters.append(chapter_lessons)
                lesson_index += chapter_lesson_count
            
            distribution[week] = week_chapters
        
        return distribution
    
    def add_practice_sessions_to_week(self, week_lessons: List[List[Dict[str, str]]], week_num: int) -> List[List[Dict[str, str]]]:
        """Add practice sessions, live sessions, and weekly reviews to each chapter in a week.
        
        Ensures each chapter has NUM_LESSONS_PER_CHAPTER lessons by generating practice sessions
        if needed. Then adds live sessions and weekly reviews.
        If USE_CUSTOM_WEEKLY_REVIEW_DAYS is True and a custom review day is defined for this week,
        the last chapter is replaced entirely with the custom content.
        """
        # Check if we should use custom weekly review day for the last chapter
        if USE_CUSTOM_WEEKLY_REVIEW_DAYS:
            if USE_SAME_REVIEW_FOR_ALL_WEEKS:
                # Use the same review day for all weeks
                use_custom_review = True
                custom_review_content = DEFAULT_WEEKLY_REVIEW_DAY
            else:
                # Use week-specific review days
                use_custom_review = week_num in CUSTOM_WEEKLY_REVIEW_DAYS
                custom_review_content = CUSTOM_WEEKLY_REVIEW_DAYS.get(week_num, [])
        else:
            use_custom_review = False
            custom_review_content = []
        
        last_chapter_index = len(week_lessons) - 1
        
        week_lessons_with_practice = []
        
        # Calculate how many practice sessions each chapter needs (excluding custom review day)
        # Handle fractional NUM_LESSONS_PER_CHAPTER (e.g., 4.5 means 3 regular sessions + 1 longer session)
        num_lessons_int = int(NUM_LESSONS_PER_CHAPTER)
        num_lessons_fractional = NUM_LESSONS_PER_CHAPTER - num_lessons_int
        has_fractional = num_lessons_fractional > 0
        
        practice_sessions_needed = []
        practice_sessions_has_extra_long = []  # Track which chapters need an extra-long session
        for chapter_idx, chapter_lessons in enumerate(week_lessons):
            if use_custom_review and chapter_idx == last_chapter_index:
                # Skip practice session calculation for custom review day
                practice_sessions_needed.append(0)
                practice_sessions_has_extra_long.append(False)
            else:
                regular_lessons_count = len(chapter_lessons)
                # Calculate total lessons needed (including fractional part)
                total_lessons_needed = NUM_LESSONS_PER_CHAPTER - regular_lessons_count
                
                if total_lessons_needed <= 0:
                    # Already have enough lessons
                    practice_sessions_needed.append(0)
                    practice_sessions_has_extra_long.append(False)
                elif has_fractional:
                    # For fractional NUM_LESSONS_PER_CHAPTER (e.g., 4.5):
                    # If we need 4.5 lessons, we want 3 regular + 1 longer (1.5x) = 3 + 1.5 = 4.5
                    # So base_sessions = int(total_needed) - 1 = int(4.5) - 1 = 4 - 1 = 3
                    # Then add 1 more for the longer session = 4 total, but last one is 1.5x
                    base_sessions = max(0, int(total_lessons_needed) - 1)
                    practice_sessions_needed.append(base_sessions + 1)  # +1 for the longer session
                    practice_sessions_has_extra_long.append(True)
                else:
                    # No fractional part, just use integer
                    practice_sessions_needed.append(max(0, int(total_lessons_needed)))
                    practice_sessions_has_extra_long.append(False)
        
        # Generate practice sessions for chapters that need them (excluding custom review day)
        chapters_needing_practice = [ch for idx, ch in enumerate(week_lessons) if not (use_custom_review and idx == last_chapter_index)]
        practice_sessions_needed_filtered = [count for idx, count in enumerate(practice_sessions_needed) if not (use_custom_review and idx == last_chapter_index)]
        practice_sessions_has_extra_long_filtered = [flag for idx, flag in enumerate(practice_sessions_has_extra_long) if not (use_custom_review and idx == last_chapter_index)]
        
        all_practice_sessions = []
        if sum(practice_sessions_needed_filtered) > 0:
            all_practice_sessions = self.generate_practice_sessions_for_week(
                chapters_needing_practice, 
                week_num, 
                practice_sessions_needed_filtered,
                practice_sessions_has_extra_long_filtered,
                num_lessons_fractional
            )
        
        # Insert practice sessions back into the full list (skipping custom review day position)
        practice_sessions_with_gaps = []
        practice_idx = 0
        for chapter_idx in range(len(week_lessons)):
            if use_custom_review and chapter_idx == last_chapter_index:
                practice_sessions_with_gaps.append([])
            else:
                practice_sessions_with_gaps.append(all_practice_sessions[practice_idx])
                practice_idx += 1
        
        for chapter_num, (chapter_lessons, practice_sessions) in enumerate(zip(week_lessons, practice_sessions_with_gaps), 1):
            # Get the original_unit from the first lesson in this chapter (for inheritance)
            chapter_unit = chapter_lessons[0].get('original_unit', 'Default Unit') if chapter_lessons else 'Default Unit'
            
            # Check if this is the custom review day
            if use_custom_review and chapter_num - 1 == last_chapter_index:
                # Start with custom review day content (don't add start/end of day items)
                custom_review_items = []
                for item in custom_review_content:
                    item_copy = item.copy()
                    if 'time_minutes' not in item_copy:
                        item_copy['time_minutes'] = BASE_TIME_ESTIMATES.get("weekly review", 240)
                    item_copy['original_unit'] = chapter_unit
                    custom_review_items.append(item_copy)
                
                week_lessons_with_practice.append(custom_review_items)
            else:
                # Start with original lessons
                chapter_with_practice = chapter_lessons.copy()
                
                # Add practice sessions to the chapter (with original_unit)
                for session in practice_sessions:
                    session_copy = session.copy()
                    session_copy['original_unit'] = chapter_unit
                    chapter_with_practice.append(session_copy)
                
                # Add items at start of day (in reverse order so first one is at the start)
                for item in reversed(ITEMS_AT_START_OF_DAY):
                    item_copy = item.copy()
                    item_copy['original_unit'] = chapter_unit
                    chapter_with_practice = [item_copy] + chapter_with_practice
                
                # Add items at end of day
                for item in ITEMS_AT_END_OF_DAY:
                    item_copy = item.copy()
                    item_copy['original_unit'] = chapter_unit
                    chapter_with_practice.append(item_copy)
                
                week_lessons_with_practice.append(chapter_with_practice)
        
        # Add default weekly review to the last chapter if not using custom review day
        if week_lessons_with_practice and not use_custom_review:
            # Get unit from last chapter's first lesson
            last_chapter_unit = 'Default Unit'
            if week_lessons_with_practice[-1]:
                last_chapter_unit = week_lessons_with_practice[-1][0].get('original_unit', 'Default Unit')
            
            for _ in range(NUM_WEEKLY_REVIEW_PER_WEEK):
                weekly_review = {
                    'title': WEEKLY_REVIEW_TITLE,
                    'learning_outcomes': 'Review the concepts learned in this week and complete weekly assessment.',
                    'time_minutes': BASE_TIME_ESTIMATES.get("weekly review", 240),
                    'type': LESSON_TYPE_ASSESSMENT,
                    'original_unit': last_chapter_unit
                }
                week_lessons_with_practice[-1].append(weekly_review)
        
        return week_lessons_with_practice
    
    def generate_practice_sessions_for_week(self, week_lessons: List[List[Dict[str, str]]], week_num: int, practice_sessions_needed: List[int], has_extra_long: List[bool] = None, fractional_part: float = 0.0) -> List[List[Dict[str, str]]]:
        """Generate practice sessions for all chapters in a week using ONE AI call.
        
        Args:
            week_lessons: List of chapters, each containing a list of lessons
            week_num: Week number
            practice_sessions_needed: List of practice session counts needed per chapter
            has_extra_long: List indicating if each chapter needs an extra-long session (for fractional NUM_LESSONS_PER_CHAPTER)
            fractional_part: Fractional part of NUM_LESSONS_PER_CHAPTER (e.g., 0.5 for 9.5)
        """
        if has_extra_long is None:
            has_extra_long = [False] * len(week_lessons)
        # Build prompt with all chapters
        chapters_text = ""
        for chapter_num, chapter_lessons in enumerate(week_lessons, 1):
            lessons_text = "\n".join([f"  - {lesson['title']}: {lesson['learning_outcomes']}" for lesson in chapter_lessons])
            chapters_text += f"\nCHAPTER {chapter_num}:\n{lessons_text}\n"
        
        total_sessions = sum(practice_sessions_needed)
        
        prompt = get_practice_sessions_for_week_prompt(
            chapters_text, 
            week_num, 
            len(week_lessons), 
            practice_sessions_needed, 
            total_sessions
        )
        
        try:
            client = self._get_openai_client()
            sessions_summary = ", ".join([f"Ch{i+1}: {count}" for i, count in enumerate(practice_sessions_needed)])
            print(f"Generating practice sessions for Week {week_num} ({len(week_lessons)} chapters, {sessions_summary}, total {total_sessions} sessions)...")
            
            # Use streaming for real-time feedback
            stream = client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                **self._get_max_tokens_param(2000),  # Increased for multiple chapters
                temperature=0.7,
                stream=True
            )
            
            # Collect chunks and track usage
            ai_content = ""
            usage_data = None
            for chunk in stream:
                # Skip chunks without choices
                if not chunk.choices or len(chunk.choices) == 0:
                    continue
                    
                if chunk.choices[0].delta.content is not None:
                    content_chunk = chunk.choices[0].delta.content
                    ai_content += content_chunk
                    # Show progress
                    if len(ai_content) % 100 == 0:
                        print(".", end="", flush=True)
                # Capture usage data from the final chunk
                if hasattr(chunk, 'usage') and chunk.usage is not None:
                    usage_data = chunk.usage
            
            print()  # New line after progress dots
            
            # Display cost information
            if usage_data:
                cost = self._calculate_cost(usage_data.prompt_tokens, usage_data.completion_tokens)
                print(f"ðŸ“Š Tokens: {usage_data.prompt_tokens:,} in + {usage_data.completion_tokens:,} out = {usage_data.total_tokens:,} total | ðŸ’° ${cost:.4f}")
            
            # Log the API call
            self._log_api_call(prompt, ai_content, f"WEEK {week_num} ALL CHAPTERS PRACTICE SESSIONS (STREAMED)")
            
            # Parse the structured response grouped by chapter
            all_practice_sessions = []
            current_chapter_sessions = []
            current_session = {}
            
            lines = ai_content.split('\n')
            for line in lines:
                line = line.strip()
                if line.startswith('CHAPTER:'):
                    # Save previous chapter's sessions if any
                    if current_session and current_session.get('title'):
                        current_chapter_sessions.append(current_session)
                        current_session = {}
                    if current_chapter_sessions:
                        all_practice_sessions.append(current_chapter_sessions)
                        current_chapter_sessions = []
                elif line.startswith('TITLE:'):
                    if current_session and current_session.get('title'):
                        current_chapter_sessions.append(current_session)
                    current_session = {'title': line[6:].strip(), 'learning_outcomes': '', 'type': LESSON_TYPE_EXERCISE}
                elif line.startswith('OUTCOMES:'):
                    if current_session:
                        current_session['learning_outcomes'] = line[9:].strip()
            
            # Add the last session and chapter
            if current_session and current_session.get('title'):
                current_chapter_sessions.append(current_session)
            if current_chapter_sessions:
                all_practice_sessions.append(current_chapter_sessions)
            
            # Validate we have the right number of chapters
            if len(all_practice_sessions) != len(week_lessons):
                raise ValueError(f"Mismatch in chapter count: expected {len(week_lessons)}, got {len(all_practice_sessions)}")
            
            # Validate each chapter has the correct number of practice sessions
            for chapter_idx, (expected_count, actual_sessions) in enumerate(zip(practice_sessions_needed, all_practice_sessions), 1):
                if len(actual_sessions) != expected_count:
                    print(f"Warning: Chapter {chapter_idx} expected {expected_count} practice sessions but got {len(actual_sessions)}")
            
            # Apply extra time to the last practice session in chapters that need it (for fractional NUM_LESSONS_PER_CHAPTER)
            if fractional_part > 0:
                for chapter_idx, (chapter_sessions, needs_extra_long) in enumerate(zip(all_practice_sessions, has_extra_long)):
                    if needs_extra_long and chapter_sessions:
                        # Get the base time for a practice session
                        base_practice_time = BASE_TIME_ESTIMATES.get("practice", 30)
                        # Calculate extra time (half a lesson length = fractional_part of base time)
                        extra_time = int(base_practice_time * fractional_part)
                        # Add extra time to the last practice session
                        last_session = chapter_sessions[-1]
                        if 'time_minutes' not in last_session:
                            last_session['time_minutes'] = base_practice_time + extra_time
                        else:
                            last_session['time_minutes'] = last_session['time_minutes'] + extra_time
                        last_session['_is_extra_long'] = True  # Mark for reference
            
            print(f"Generated {sum(len(sessions) for sessions in all_practice_sessions)} practice sessions across {len(all_practice_sessions)} chapters")
            return all_practice_sessions
            
        except Exception as e:
            print(f"Error generating practice sessions for week: {e}")
            raise RuntimeError(f"Failed to generate practice sessions for week {week_num}: {e}")
    
    def generate_learning_goals(self, week_lessons: List[List[Dict[str, str]]], week_num: int) -> Tuple[str, List[List[Dict[str, str]]]]:
        """Generate learning goals for a week using OpenAI and return lessons with live sessions and reviews."""
        # Add live sessions and weekly reviews to each chapter
        week_lessons_with_practice = self.add_practice_sessions_to_week(week_lessons, week_num)
        
        all_lessons = [lesson for chapter in week_lessons_with_practice for lesson in chapter]
        lessons_text = "\n".join([f"- {lesson['title']}: {lesson['learning_outcomes']}" for lesson in all_lessons])
        
        prompt = get_week_learning_goals_prompt(lessons_text, week_num)
        
        try:
            client = self._get_openai_client()
            
            # Use streaming for real-time feedback
            stream = client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                **self._get_max_tokens_param(200),
                temperature=0.7,
                stream=True
            )
            
            # Collect chunks and track usage
            result = ""
            usage_data = None
            for chunk in stream:
                # Skip chunks without choices
                if not chunk.choices or len(chunk.choices) == 0:
                    continue
                    
                if chunk.choices[0].delta.content is not None:
                    result += chunk.choices[0].delta.content
                # Capture usage data from the final chunk
                if hasattr(chunk, 'usage') and chunk.usage is not None:
                    usage_data = chunk.usage
            
            result = result.strip()
            
            # Display cost information
            if usage_data:
                cost = self._calculate_cost(usage_data.prompt_tokens, usage_data.completion_tokens)
                print(f"ðŸ“Š Tokens: {usage_data.prompt_tokens:,} in + {usage_data.completion_tokens:,} out = {usage_data.total_tokens:,} total | ðŸ’° ${cost:.4f}")
            
            # Log the API call
            self._log_api_call(prompt, result, f"WEEK {week_num} LEARNING GOALS (STREAMED)")
            
            return result, week_lessons_with_practice
        except Exception as e:
            print(f"Error generating learning goals: {e}")
            raise RuntimeError(f"Failed to generate learning goals for week {week_num}: {e}")
    
    def generate_chapter_info(self, chapter_lessons: List[Dict[str, str]], week_num: int, chapter_num: int) -> Tuple[str, str]:
        """Generate chapter title and learning goals using OpenAI."""
        lessons_text = "\n".join([f"- {lesson['title']}: {lesson['learning_outcomes']}" for lesson in chapter_lessons])
        
        prompt = get_chapter_info_prompt(lessons_text)
        
        try:
            client = self._get_openai_client()
            
            # Use streaming for real-time feedback
            stream = client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                **self._get_max_tokens_param(150),
                temperature=0.7,
                stream=True
            )
            
            # Collect chunks and track usage
            content = ""
            usage_data = None
            for chunk in stream:
                # Skip chunks without choices
                if not chunk.choices or len(chunk.choices) == 0:
                    continue
                    
                if chunk.choices[0].delta.content is not None:
                    content += chunk.choices[0].delta.content
                # Capture usage data from the final chunk
                if hasattr(chunk, 'usage') and chunk.usage is not None:
                    usage_data = chunk.usage
            
            content = content.strip()
            
            # Display cost information
            if usage_data:
                cost = self._calculate_cost(usage_data.prompt_tokens, usage_data.completion_tokens)
                print(f"ðŸ“Š Tokens: {usage_data.prompt_tokens:,} in + {usage_data.completion_tokens:,} out = {usage_data.total_tokens:,} total | ðŸ’° ${cost:.4f}")
            
            # Log the API call
            self._log_api_call(prompt, content, f"WEEK {week_num} CHAPTER {chapter_num} INFO (STREAMED)")
            
            # Parse TITLE and GOALS from response (more robust parsing)
            title = "Chapter"
            goals = "Learn key concepts"
            
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line.startswith('TITLE:'):
                    title = line.replace('TITLE:', '').strip()
                elif line.startswith('GOALS:'):
                    goals = line.replace('GOALS:', '').strip()
            
            # Fallback if TITLE not found - use first non-empty line
            if title == "Chapter":
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('GOALS:'):
                        title = line
                        break
            
            return title, goals
        except Exception as e:
            print(f"Error generating chapter info: {e}")
            raise RuntimeError(f"Failed to generate chapter info for week {week_num}, chapter {chapter_num}: {e}")
    
    def get_lesson_type(self, lesson: Dict[str, str]) -> str:
        """Determine the learning media type for a lesson."""
        # Check if type is explicitly defined in the lesson
        if 'type' in lesson:
            return lesson['type']
        
        title_lower = lesson['title'].lower()
        
        # Check for live session / sync class keywords
        live_session_keywords = ['session', 'q&a', 'qa', 'sync', 'live', 'group', 'opening', 'closing']
        if any(keyword in title_lower for keyword in live_session_keywords):
            return LESSON_TYPE_SYNC
        
        # Check for Assessment keywords
        assessment_keywords = ['assessment', 'exam', 'test', 'quiz', 'evaluation']
        if any(keyword in title_lower for keyword in assessment_keywords):
            return LESSON_TYPE_ASSESSMENT
        
        # Check for Practice Session / Exercise keywords
        exercise_keywords = ['practice session', 'exercise', 'practice', 'hands-on', 'workshop']
        if any(keyword in title_lower for keyword in exercise_keywords):
            return LESSON_TYPE_EXERCISE
        
        # Default to Lesson
        return LESSON_TYPE_LESSON
    
    def estimate_lesson_time(self, lesson: Dict[str, str], week_lessons: List[List[Dict[str, str]]]) -> int:
        """Estimate time to complete a lesson in minutes."""
        # Check if lesson already has a time stored (e.g., from live sessions)
        if 'time_minutes' in lesson:
            return lesson['time_minutes']
        
        # Simple estimation based on lesson title keywords
        title_lower = lesson['title'].lower()
        
        # Look up base time from dictionary
        base_time = BASE_TIME_ESTIMATES["default"]
        for keyword, time in BASE_TIME_ESTIMATES.items():
            if keyword != "default" and keyword in title_lower:
                base_time = time
                break
        
        # Check if it's an item from start/end of day lists
        for item in ITEMS_AT_START_OF_DAY + ITEMS_AT_END_OF_DAY:
            if item['title'].lower() in title_lower:
                base_time = item.get('time_minutes', BASE_TIME_ESTIMATES.get("sync session", 90))
                break
        
        return max(30, base_time)  # Minimum 30 minutes
    
    def adjust_times_to_30_hours(self, week_lessons: List[List[Dict[str, str]]], estimated_times: List[List[int]]) -> List[List[int]]:
        """Adjust lesson times so the week totals exactly 30 hours (1800 minutes)."""
        total_estimated = sum(sum(chapter_times) for chapter_times in estimated_times)
        target_minutes = 1800  # 30 hours
        
        if total_estimated == 0:
            return estimated_times
        
        # Calculate scaling factor
        scale_factor = target_minutes / total_estimated
        
        # Apply scaling and round to nearest 5 minutes
        adjusted_times = []
        for chapter_times in estimated_times:
            adjusted_chapter = []
            for time in chapter_times:
                adjusted_time = round(time * scale_factor / 5) * 5
                adjusted_time = max(15, adjusted_time)  # Minimum 15 minutes
                adjusted_chapter.append(adjusted_time)
            adjusted_times.append(adjusted_chapter)
        
        return adjusted_times
    
    def setup_worksheet_headers(self):
        """Set up the worksheet headers and formatting."""
        headers = [
            "Week", "Learning Goal of the week", "Chapter number", 
            "Chapter learning goals", "Chapter title", "Learning Media", "Lesson title", "Time to complete", "Mastery Outcome"
        ]
        
        # Set headers
        for col, header in enumerate(headers, 1):
            cell = self.worksheet.cell(row=1, column=col, value=header)
            cell.font = Font(bold=True)
            cell.alignment = Alignment(horizontal='center', vertical='center')
        
        # Set column widths
        column_widths = [8, 50, 15, 40, 25, 15, 35, 15, 50]
        for col, width in enumerate(column_widths, 1):
            self.worksheet.column_dimensions[get_column_letter(col)].width = width
    
    def add_week_data(self, week_num: int, week_lessons: List[List[Dict[str, str]]], week_learning_goal: str):
        """Add data for one week to the worksheet."""
        current_row = self.worksheet.max_row + 1
        
        # Estimate times for all lessons
        estimated_times = []
        for chapter_lessons in week_lessons:
            chapter_times = [self.estimate_lesson_time(lesson, week_lessons) for lesson in chapter_lessons]
            estimated_times.append(chapter_times)
        
        # Adjust times to total 30 hours
        adjusted_times = estimated_times
        
        # Check if this week uses custom review days
        is_custom_review_week = False
        if USE_CUSTOM_WEEKLY_REVIEW_DAYS:
            if USE_SAME_REVIEW_FOR_ALL_WEEKS:
                is_custom_review_week = True
            else:
                is_custom_review_week = week_num in CUSTOM_WEEKLY_REVIEW_DAYS
        
        # Add data for each chapter
        for chapter_num, (chapter_lessons, chapter_times) in enumerate(zip(week_lessons, adjusted_times), 1):
            # Check if this is the custom review day (last chapter)
            is_custom_review_day = is_custom_review_week and chapter_num == len(week_lessons)
            
            if is_custom_review_day:
                # Use custom chapter title and goals
                chapter_title = DEFAULT_WEEKLY_REVIEW_CHAPTER_TITLE
                chapter_goals = DEFAULT_WEEKLY_REVIEW_CHAPTER_GOALS
            else:
                # Generate chapter info using AI
                chapter_title, chapter_goals = self.generate_chapter_info(chapter_lessons, week_num, chapter_num)
            
            chapter_start_row = current_row
            
            for lesson_num, (lesson, time) in enumerate(zip(chapter_lessons, chapter_times)):
                # Week column (merged for all lessons in the week)
                if chapter_num == 1 and lesson_num == 0:
                    week_cell = self.worksheet.cell(row=current_row, column=1, value=week_num)
                    week_cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Learning goal column (merged for all lessons in the week)
                if chapter_num == 1 and lesson_num == 0:
                    goal_cell = self.worksheet.cell(row=current_row, column=2, value=week_learning_goal)
                    goal_cell.alignment = Alignment(vertical='top', wrap_text=True)
                
                # Chapter number (only set on first lesson of chapter)
                if lesson_num == 0:
                    chapter_cell = self.worksheet.cell(row=current_row, column=3, value=f"{week_num}.{chapter_num}")
                    chapter_cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Chapter learning goals (only set on first lesson of chapter)
                if lesson_num == 0:
                    goals_cell = self.worksheet.cell(row=current_row, column=4, value=chapter_goals)
                    goals_cell.alignment = Alignment(vertical='top', wrap_text=True)
                
                # Chapter title (only set on first lesson of chapter)
                if lesson_num == 0:
                    title_cell = self.worksheet.cell(row=current_row, column=5, value=chapter_title)
                    title_cell.alignment = Alignment(vertical='top')
                
                # Learning Media (column 6)
                lesson_type = self.get_lesson_type(lesson)
                type_cell = self.worksheet.cell(row=current_row, column=6, value=lesson_type)
                type_cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Lesson title
                lesson_cell = self.worksheet.cell(row=current_row, column=7, value=lesson['title'])
                lesson_cell.alignment = Alignment(vertical='top')
                
                # Time to complete
                time_cell = self.worksheet.cell(row=current_row, column=8, value=f"{time}")
                time_cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Mastery Outcome
                outcome_cell = self.worksheet.cell(row=current_row, column=9, value=lesson['learning_outcomes'])
                outcome_cell.alignment = Alignment(vertical='top', wrap_text=True)
                
                current_row += 1
            
            # Merge cells for chapter columns (chapter number, goals, title)
            chapter_end_row = current_row - 1
            if chapter_start_row < chapter_end_row:
                self.worksheet.merge_cells(f'C{chapter_start_row}:C{chapter_end_row}')
                self.worksheet.merge_cells(f'D{chapter_start_row}:D{chapter_end_row}')
                self.worksheet.merge_cells(f'E{chapter_start_row}:E{chapter_end_row}')
        
        # Merge cells for week and learning goal columns
        start_row = current_row - sum(len(chapter) for chapter in week_lessons)
        end_row = current_row - 1
        
        # Merge week column
        if start_row < end_row:
            self.worksheet.merge_cells(f'A{start_row}:A{end_row}')
            self.worksheet.merge_cells(f'B{start_row}:B{end_row}')
    
    def save_syllabus_json(self, lessons: List[Dict[str, str]], weeks_data: Dict[int, Tuple[str, List[List[Dict[str, str]]]]], num_practice_sessions: int, json_file: str = None):
        """Save complete syllabus data to a JSON file.
        
        Args:
            lessons: Original list of lessons
            weeks_data: Dictionary mapping week_num to (learning_goal, week_lessons_with_practice)
            num_practice_sessions: Number of practice sessions per chapter
            json_file: Path to the JSON file (if None, auto-generates from output filename)
        """
        if json_file is None:
            json_file = 'output/syllabus_data.json'
        
        # Ensure output directory exists
        os.makedirs(os.path.dirname(json_file) if os.path.dirname(json_file) else '.', exist_ok=True)
        
        # Organize all data for JSON export (only content that makes up the XLSX)
        json_data = {
            'num_weeks': NUM_OF_WEEKS,
            'num_chapters_per_week': NUM_OF_CHAPTERS_PER_WEEK,
            'num_practice_sessions': num_practice_sessions,
            'weeks': {}
        }
        
        # Collect detailed week data
        for week_num, (week_learning_goal, week_lessons_with_practice) in weeks_data.items():
            # Estimate times for all lessons in this week
            estimated_times = []
            for chapter_lessons in week_lessons_with_practice:
                chapter_times = [self.estimate_lesson_time(lesson, week_lessons_with_practice) for lesson in chapter_lessons]
                estimated_times.append(chapter_times)
            
            # Collect week data
            week_data = {
                'week_num': week_num,
                'learning_goal': week_learning_goal,
                'chapters': []
            }
            
            # Check if this week uses custom review days
            is_custom_review_week = False
            if USE_CUSTOM_WEEKLY_REVIEW_DAYS:
                if USE_SAME_REVIEW_FOR_ALL_WEEKS:
                    is_custom_review_week = True
                else:
                    is_custom_review_week = week_num in CUSTOM_WEEKLY_REVIEW_DAYS
            
            for chapter_num, chapter_lessons in enumerate(week_lessons_with_practice, 1):
                # Check if this is the custom review day (last chapter)
                is_custom_review_day = is_custom_review_week and chapter_num == len(week_lessons_with_practice)
                
                if is_custom_review_day:
                    # Use custom chapter title and goals
                    chapter_title = DEFAULT_WEEKLY_REVIEW_CHAPTER_TITLE
                    chapter_goals = DEFAULT_WEEKLY_REVIEW_CHAPTER_GOALS
                else:
                    # Generate chapter info using AI
                    chapter_title, chapter_goals = self.generate_chapter_info(chapter_lessons, week_num, chapter_num)
                
                chapter_data = {
                    'chapter_num': chapter_num,
                    'title': chapter_title,
                    'learning_goals': chapter_goals,
                    'lessons': []
                }
                
                # Add lessons with times and types
                chapter_times = estimated_times[chapter_num - 1]
                for lesson, time in zip(chapter_lessons, chapter_times):
                    lesson_data = {
                        'title': lesson['title'],
                        'learning_outcomes': lesson['learning_outcomes'],
                        'time_minutes': time,
                        'type': self.get_lesson_type(lesson),
                        'original_unit': lesson.get('original_unit', 'Default Unit')
                    }
                    chapter_data['lessons'].append(lesson_data)
                
                week_data['chapters'].append(chapter_data)
            
            json_data['weeks'][week_num] = week_data
        
        # Save to JSON file
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        print(f"JSON exported to {json_file}")
    
    def load_syllabus_from_json(self, json_file: str) -> Dict:
        """Load syllabus data from a JSON file.
        
        Args:
            json_file: Path to the JSON file
            
        Returns:
            Dictionary containing the syllabus data
        """
        with open(json_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def add_week_data_from_json(self, week_num: int, week_data: Dict, week_learning_goal: str):
        """Add data for one week to the worksheet from JSON data (no AI calls needed).
        
        Args:
            week_num: Week number
            week_data: Week data from JSON with chapters containing title and learning_goals
            week_learning_goal: Learning goal for the week
        """
        current_row = self.worksheet.max_row + 1
        
        # Extract lessons and times from JSON
        week_lessons = []
        adjusted_times = []
        
        for chapter_data in week_data['chapters']:
            chapter_lessons = []
            chapter_times = []
            for lesson_data in chapter_data['lessons']:
                lesson = {
                    'title': lesson_data['title'],
                    'learning_outcomes': lesson_data['learning_outcomes'],
                    'time_minutes': lesson_data.get('time_minutes', 30),
                    'type': lesson_data.get('type', LESSON_TYPE_LESSON)
                }
                chapter_lessons.append(lesson)
                chapter_times.append(lesson_data.get('time_minutes', 30))
            week_lessons.append(chapter_lessons)
            adjusted_times.append(chapter_times)
        
        # Add data for each chapter
        for chapter_num, (chapter_lessons, chapter_times, chapter_data) in enumerate(zip(week_lessons, adjusted_times, week_data['chapters']), 1):
            # Use chapter title and goals from JSON
            chapter_title = chapter_data['title']
            chapter_goals = chapter_data['learning_goals']
            
            chapter_start_row = current_row
            
            for lesson_num, (lesson, time) in enumerate(zip(chapter_lessons, chapter_times)):
                # Week column (merged for all lessons in the week)
                if chapter_num == 1 and lesson_num == 0:
                    week_cell = self.worksheet.cell(row=current_row, column=1, value=week_num)
                    week_cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Learning goal column (merged for all lessons in the week)
                if chapter_num == 1 and lesson_num == 0:
                    goal_cell = self.worksheet.cell(row=current_row, column=2, value=week_learning_goal)
                    goal_cell.alignment = Alignment(vertical='top', wrap_text=True)
                
                # Chapter number (only set on first lesson of chapter)
                if lesson_num == 0:
                    chapter_cell = self.worksheet.cell(row=current_row, column=3, value=f"{week_num}.{chapter_num}")
                    chapter_cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Chapter learning goals (only set on first lesson of chapter)
                if lesson_num == 0:
                    goals_cell = self.worksheet.cell(row=current_row, column=4, value=chapter_goals)
                    goals_cell.alignment = Alignment(vertical='top', wrap_text=True)
                
                # Chapter title (only set on first lesson of chapter)
                if lesson_num == 0:
                    title_cell = self.worksheet.cell(row=current_row, column=5, value=chapter_title)
                    title_cell.alignment = Alignment(vertical='top')
                
                # Learning Media (column 6)
                lesson_type = self.get_lesson_type(lesson)
                type_cell = self.worksheet.cell(row=current_row, column=6, value=lesson_type)
                type_cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Lesson title
                lesson_cell = self.worksheet.cell(row=current_row, column=7, value=lesson['title'])
                lesson_cell.alignment = Alignment(vertical='top')
                
                # Time to complete
                time_cell = self.worksheet.cell(row=current_row, column=8, value=f"{time}")
                time_cell.alignment = Alignment(horizontal='center', vertical='center')
                
                # Mastery Outcome
                outcome_cell = self.worksheet.cell(row=current_row, column=9, value=lesson['learning_outcomes'])
                outcome_cell.alignment = Alignment(vertical='top', wrap_text=True)
                
                current_row += 1
            
            # Merge cells for chapter columns (chapter number, goals, title)
            chapter_end_row = current_row - 1
            if chapter_start_row < chapter_end_row:
                self.worksheet.merge_cells(f'C{chapter_start_row}:C{chapter_end_row}')
                self.worksheet.merge_cells(f'D{chapter_start_row}:D{chapter_end_row}')
                self.worksheet.merge_cells(f'E{chapter_start_row}:E{chapter_end_row}')
        
        # Merge cells for week and learning goal columns
        start_row = current_row - sum(len(chapter) for chapter in week_lessons)
        end_row = current_row - 1
        
        # Merge week column
        if start_row < end_row:
            self.worksheet.merge_cells(f'A{start_row}:A{end_row}')
            self.worksheet.merge_cells(f'B{start_row}:B{end_row}')
    
    def generate_syllabus_from_json(self, json_file: str, output_file: str):
        """Generate Excel file from JSON syllabus data.
        
        Args:
            json_file: Path to the JSON file containing syllabus data
            output_file: Output Excel file name
        """
        print(f"Loading syllabus from JSON file: {json_file}")
        json_data = self.load_syllabus_from_json(json_file)
        
        print("Setting up worksheet...")
        self.setup_worksheet_headers()
        
        # Add data to worksheet directly from JSON (no AI calls needed)
        for week_num in sorted(json_data['weeks'].keys(), key=int):
            week_data = json_data['weeks'][week_num]
            week_learning_goal = week_data['learning_goal']
            self.add_week_data_from_json(int(week_num), week_data, week_learning_goal)
            print(f"Week {week_num} completed")
        
        # Ensure output directory exists
        os.makedirs('output', exist_ok=True)
        
        print(f"Saving syllabus to {output_file}...")
        self.workbook.save("output/" + output_file)
        print("Syllabus generated successfully from JSON!")
    
    def export_maestro_json(self, lessons: List[Dict[str, str]], weeks_data: Dict[int, Tuple[str, List[List[Dict[str, str]]]]], output_file: str):
        """Export syllabus data to Maestro JSON format using AI transformation."""
        # Build the lesson data organized by week
        weeks_lessons_text = ""
        for week_num in range(START_WEEK_NUM, START_WEEK_NUM + NUM_OF_WEEKS):
            if week_num in weeks_data:
                week_learning_goal, week_lessons_with_practice = weeks_data[week_num]
                weeks_lessons_text += f"\n\nWEEK {week_num} - {week_learning_goal}\n"
                weeks_lessons_text += "Lessons:\n"
                
                # Flatten all lessons from all chapters in this week
                for chapter_lessons in week_lessons_with_practice:
                    for lesson in chapter_lessons:
                        is_practice = "practice session" in lesson['title'].lower()
                        marker = "[PRACTICE]" if is_practice else ""
                        weeks_lessons_text += f"  - {marker} {lesson['title']}: {lesson['learning_outcomes']}\n"
        
        # Build dynamic template structure based on NUM_OF_WEEKS
        template_units = []
        for i in range(START_WEEK_NUM, START_WEEK_NUM + NUM_OF_WEEKS):
            template_units.append(f'''            {{
              "title": "Unit {i} Title Placeholder",
              "lessons": [
                {{
                  "title": "Lesson 1 Title Placeholder",
                  "masteryOutcomes": [
                    "Single mastery outcome placeholder"
                  ],
                  "teachingInstructions": ""
                }}
              ]
            }}''')
        
        units_template = ",\n".join(template_units)
        
        prompt = get_maestro_json_prompt(units_template, NUM_OF_WEEKS, weeks_lessons_text)
        
        try:
            client = self._get_openai_client()
            print(f"Generating Maestro JSON export...")
            
            # Use streaming for real-time feedback
            # Note: gpt-4 has 8K context, gpt-4-turbo has 128K
            # Adjust max_tokens based on available context after prompt
            stream = client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                **self._get_max_tokens_param(3600),  # Balanced for gpt-4; use gpt-4-turbo for larger outputs
                temperature=0.3,
                stream=True
            )
            
            # Collect chunks and track usage
            ai_content = ""
            usage_data = None
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content_chunk = chunk.choices[0].delta.content
                    ai_content += content_chunk
                    # Show progress
                    if len(ai_content) % 200 == 0:
                        print(".", end="", flush=True)
                # Capture usage data from the final chunk
                if hasattr(chunk, 'usage') and chunk.usage is not None:
                    usage_data = chunk.usage
            
            print()  # New line after progress dots
            
            # Display cost information
            if usage_data:
                cost = self._calculate_cost(usage_data.prompt_tokens, usage_data.completion_tokens)
                print(f"ðŸ“Š Tokens: {usage_data.prompt_tokens:,} in + {usage_data.completion_tokens:,} out = {usage_data.total_tokens:,} total | ðŸ’° ${cost:.4f}")
            
            # Log the API call
            self._log_api_call(prompt, ai_content, "MAESTRO JSON EXPORT")
            
            # Clean up the response - extract JSON from markdown or plain text
            ai_content = ai_content.strip()
            
            # Try to extract JSON from markdown code blocks
            if '```json' in ai_content:
                # Extract content between ```json and ```
                start = ai_content.find('```json') + 7
                end = ai_content.find('```', start)
                if end != -1:
                    ai_content = ai_content[start:end].strip()
            elif '```' in ai_content:
                # Extract content between ``` and ```
                start = ai_content.find('```') + 3
                end = ai_content.find('```', start)
                if end != -1:
                    ai_content = ai_content[start:end].strip()
            
            # Try to find JSON object by looking for opening and closing braces
            if not ai_content.startswith('{'):
                # Find the first { in the content
                json_start = ai_content.find('{')
                if json_start != -1:
                    ai_content = ai_content[json_start:]
            
            # Check if response was likely truncated
            if not ai_content.endswith('}'):
                print("Warning: Response appears truncated.")
                print("TIP: Run with --model gpt-4-turbo for larger context window and better JSON generation.")
            
            # Parse and validate JSON
            try:
                maestro_data = json.loads(ai_content)
                print("Successfully parsed Maestro JSON")
            except json.JSONDecodeError as e:
                print(f"Warning: AI response is not valid JSON. Error: {e}")
                print(f"Response length: {len(ai_content)} characters")
                print("TIP: Run with --model gpt-4-turbo for better JSON generation and larger context.")
                print("Attempting to save raw response for debugging...")
                maestro_data = {
                    "error": "Invalid JSON from AI", 
                    "error_message": str(e),
                    "response_length": len(ai_content),
                    "raw_response": ai_content
                }
            
            # Determine output filename
            base_name = output_file.replace('.xlsx', '').replace('.xls', '')
            maestro_file = f"output/maestro_{base_name}_{output_course_format}.json"
            
            # Ensure output directory exists
            os.makedirs('output', exist_ok=True)
            
            # Save to file
            with open(maestro_file, 'w', encoding='utf-8') as f:
                json.dump(maestro_data, f, indent=2, ensure_ascii=False)
            
            print(f"Maestro JSON exported to {maestro_file}")
            
        except Exception as e:
            print(f"Error exporting Maestro JSON: {e}")
            print("Continuing with syllabus generation...")
    
    def export_maestro_json_non_ai(self, weeks_data: Dict[int, Tuple[str, List[List[Dict[str, str]]]]], output_file: str):
        """Export syllabus data to Maestro JSON format using non-AI converter.
        
        When USE_ORIGINAL_UNITS_IN_MAESTRO is True:
            Groups lessons by their original_unit (from the input file's UNIT: headers)
            to create 4 units with original unit names.
        When False:
            Uses weeks structure (units = weeks from XLSX).
        
        Args:
            weeks_data: Dictionary mapping week_num to (learning_goal, week_lessons_with_practice)
            output_file: Output Excel file name (used to derive maestro JSON filename)
        """
        # Determine output filename
        base_name = output_file.replace('.xlsx', '').replace('.xls', '')
        maestro_file = f"output/maestro_{base_name}_{output_course_format}.json"
        
        converter = XLSXToMaestroConverter()
        
        if USE_ORIGINAL_UNITS_IN_MAESTRO:
            # Group lessons by original_unit (preserving order)
            from collections import OrderedDict
            units_data = OrderedDict()
            
            for week_num in sorted(weeks_data.keys()):
                week_learning_goal, week_lessons_with_practice = weeks_data[week_num]
                
                for chapter_lessons in week_lessons_with_practice:
                    for lesson in chapter_lessons:
                        unit_name = lesson.get('original_unit', 'Default Unit')
                        
                        if unit_name not in units_data:
                            units_data[unit_name] = {
                                'unit_name': unit_name,
                                'lessons': []
                            }
                        
                        # Estimate time for this lesson
                        time = self.estimate_lesson_time(lesson, week_lessons_with_practice)
                        
                        lesson_data = {
                            'title': lesson['title'],
                            'learning_outcomes': lesson['learning_outcomes'],
                            'time_minutes': time
                        }
                        units_data[unit_name]['lessons'].append(lesson_data)
            
            # Use the non-AI converter with unit-based data
            converter.generate_maestro_json_from_units(units_data, maestro_file, output_file)
        else:
            # Build weeks_data structure for the converter (units = weeks)
            converter_weeks_data = {}
            for week_num in sorted(weeks_data.keys()):
                week_learning_goal, week_lessons_with_practice = weeks_data[week_num]
                
                chapters = []
                for chapter_lessons in week_lessons_with_practice:
                    chapter_data = {
                        'lessons': []
                    }
                    for lesson in chapter_lessons:
                        time = self.estimate_lesson_time(lesson, week_lessons_with_practice)
                        lesson_data = {
                            'title': lesson['title'],
                            'learning_outcomes': lesson['learning_outcomes'],
                            'time_minutes': time
                        }
                        chapter_data['lessons'].append(lesson_data)
                    chapters.append(chapter_data)
                
                converter_weeks_data[week_num] = {
                    'learning_goal': week_learning_goal,
                    'chapters': chapters
                }
            
            # Use the regular weeks-based converter
            converter.generate_maestro_json(converter_weeks_data, maestro_file, output_file)
    
    def generate_syllabus(self, lessons_file: str, output_file: str):
        """Generate the complete syllabus Excel file."""
        print("Reading lessons from file...")
        lessons = self.read_lessons_from_file(lessons_file)
        print(f"Found {len(lessons)} lessons")
        
        print("Distributing lessons across weeks...")
        distribution = self.distribute_lessons(lessons)

        print("Setting up worksheet...")
        self.setup_worksheet_headers()
        
        # Store minimal week data for backup
        weeks_data = {}
        
        print("Generating learning goals and creating syllabus...")
        for week_num in range(START_WEEK_NUM, START_WEEK_NUM + NUM_OF_WEEKS):
            week_lessons = distribution[week_num]
            week_learning_goal, week_lessons_with_practice = self.generate_learning_goals(week_lessons, week_num)
            weeks_data[week_num] = (week_learning_goal, week_lessons_with_practice)
            self.add_week_data(week_num, week_lessons_with_practice, week_learning_goal)
            print(f"Week {week_num} completed")
        
        # Save all syllabus data to a JSON file
        base_name = output_file.replace('.xlsx', '').replace('.xls', '')
        json_file = f"output/{base_name}_{output_course_format}.json"
        self.save_syllabus_json(lessons, weeks_data, 0, json_file)  # No practice sessions added
        
        # Export to Maestro JSON format (non-AI)
        if EXPORT_TO_MAESTRO_JSON:
            self.export_maestro_json_non_ai(weeks_data, output_file)

        # Ensure output directory exists
        os.makedirs('output', exist_ok=True)
        
        print(f"Saving syllabus to {output_file}...")
        self.workbook.save("output/" + output_file)
        print("Syllabus generated successfully!")
        
        # Log completion
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(f"[{self._get_timestamp()}] PROCESS COMPLETED\n")
            f.write("-" * 60 + "\n")
            f.write(f"Syllabus saved to: {output_file}\n")
            f.write(f"Total lessons processed: {len(lessons)}\n")
            f.write("=" * 80 + "\n\n")

def main():
    parser = argparse.ArgumentParser(description='Generate course syllabus from lesson titles or JSON file')
    parser.add_argument('--lessons_file', help='Text file containing lesson titles (one per line)')
    parser.add_argument('--json_input', help='JSON file containing syllabus data (alternative to --lessons_file)')
    parser.add_argument('-o', '--output', default='course_syllabus.xlsx', 
                       help='Output Excel file name (default: course_syllabus.xlsx)')
    parser.add_argument('--format', choices=['part_time', 'full_time'], default='part_time',
                       help='Course format: part_time (4 weeks, 4.5 lessons/day) or full_time (2 weeks, 9 lessons/day). Default: part_time')
    parser.add_argument('--start-week', type=int, default=1,
                       help='Starting week number (default: 1). Use 3 for full_time 2nd course, 5 for part_time 2nd course.')
    parser.add_argument('--api-key', help='OpenAI API key (or set OPENAI_API_KEY environment variable)')
    parser.add_argument('--log-file', default='openai_log.txt',
                       help='Log file for OpenAI API calls (default: openai_log.txt)')
    parser.add_argument('--model', default=DEFAULT_MODEL,
                       help=f'OpenAI model to use (default: {DEFAULT_MODEL}, options: gpt-5.1, gpt-4o, gpt-4, gpt-4-turbo, gpt-3.5-turbo)')

    
    args = parser.parse_args()
    
    print(f"Using format: {output_course_format} (weeks: {NUM_OF_WEEKS}, start week: {START_WEEK_NUM}, lessons/chapter: {NUM_LESSONS_PER_CHAPTER})")
    
    # Check if using JSON input
    if args.json_input:
        # Generate from JSON (no API key needed)
        generator = SyllabusGenerator("dummy", args.log_file, DEFAULT_MODEL)  # API key not needed for JSON import
        generator.generate_syllabus_from_json(args.json_input, args.output)
    else:
        # Generate from lessons file (API key required)
        api_key = args.api_key or os.getenv('OPENAI_API_KEY')
        if not api_key:
            print("Error: OpenAI API key required. Provide via --api-key argument or OPENAI_API_KEY environment variable.")
            sys.exit(1)
        
        if not args.lessons_file:
            print("Error: Either --lessons_file or --json_input must be provided.")
            sys.exit(1)
        
        # Generate syllabus
        generator = SyllabusGenerator(api_key, args.log_file, args.model)
        generator.generate_syllabus(args.lessons_file, args.output)

if __name__ == "__main__":
    main()
