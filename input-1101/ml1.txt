## ▶️ Unit 1: Understanding AI

### 1. What Is Artificial Intelligence?

- Define Artificial Intelligence in practical, non-sci-fi terms
- Identify what makes a system “intelligent” in practice
- Distinguish AI systems from traditional software

---

### 2. A Short History of AI

- Describe how early AI systems were built
- Explain why early AI relied on rules and logic
- Identify what changed when data became central

---

### 3. Rule-Based AI

- Define rule-based (symbolic) AI
- Explain how rules are written and applied
- Identify strengths and limitations of rule-based systems

---

### 4. Data-Driven AI

- Define data-driven (statistical) AI
- Explain how data replaces explicit rules
- Describe why data-driven systems scale better

---

### 5. Symbolic vs Statistical AI

- Clearly distinguish symbolic AI from statistical AI
- Compare how each approach handles complexity
- Identify which approach powers most modern AI systems

---

### 6. Narrow AI vs General AI

- Define Narrow AI using real-world examples
- Define General AI conceptually and explain why it does not exist today
- Correct common misconceptions about AI capabilities

---

### 7. ML, DL, and LLMs

- Distinguish Machine Learning, Deep Learning, and LLMs
- Explain how these approaches relate to statistical AI
- Use correct terminology when describing modern systems

---

### 8. AI in the Real World

- Identify real-world applications of AI across industries
- Describe what type of data these systems rely on
- Explain why AI behavior depends on data quality

---

### 9. AI Limits and Responsibility

- Identify common limitations of AI systems
- Explain why AI systems can fail or behave unexpectedly
- Describe, at a high level, why AI impacts society

---

## ▶️ Unit 2: Working with Data in Python

### 1. Python’s Data Toolbox

- Explain Python’s role in data analysis workflows
- Distinguish Python libraries from core Python language features
- Identify when to use Pandas versus NumPy

### 2. DataFrames and Series

- Define DataFrame and Series using tabular data examples
- Explain how rows and columns map to DataFrame structure
- Navigate and inspect basic DataFrame components

### 3. Loading Real Data

- Load CSV data into a Pandas DataFrame
- Verify that data loaded correctly using inspection methods
- Identify basic issues immediately after loading data

### 4. Reading Data Carefully

- Inspect datasets to understand structure and content
- Identify potential data issues by scanning rows and columns
- Formulate simple questions about what the data represents

### 5. Selecting and Filtering

- Select specific columns from a DataFrame intentionally
- Filter rows using logical conditions
- Explain filtering logic clearly in plain language

### 6. Grouping Data

- Group data by categorical features using Pandas
- Apply basic aggregations such as mean and count
- Interpret grouped results in terms of real-world meaning

### 7. Derived Columns

- Create new columns derived from existing data
- Explain why derived columns can make data more useful
- Verify correctness of newly created columns

### 8. Thinking in Tables

- Reason about data transformations in terms of rows and columns
- Predict how operations will change a dataset’s structure
- Develop confidence manipulating tabular data logically

---

## ▶️ Unit 3: Cleaning and Exploring Data

### 1. Data Quality Checks

- Understand different data quality checks and why they are important
- Perform basic checks to assess data quality
- Explain why quality checks should happen before analysis

### 2. Handling Missing Values

- Apply simple strategies to handle missing data
- Explain the reasoning behind chosen handling methods
- Describe trade-offs of different missing-data approaches

### 3. Detecting and Handling Duplicates

- Identify **duplicate rows or records** in a dataset
- Distinguish between:
    - true duplicates (data entry or system errors)
    - legitimate repeated observations
- Decide when duplicates should be **removed, kept, or aggregated**, and explain why

### 4. Fixing Data Types

- Detect columns with incorrect data types
- Convert data types to enable proper analysis
- Explain why correct data types are essential

### 5. Detecting and Understanding Outliers

- Identify **outliers** using simple numerical and visual methods
- Distinguish between:
    - meaningful outliers (signals)
    - problematic outliers (errors, noise)
- Explain why outliers should be **investigated, not automatically removed**

### 6. Filtering with Purpose

- Apply filters based on meaningful conditions
- Explain why specific filters are applied
- Validate that filtering produced expected results

### 7. Grouping for Insight

- Use grouping to compare categories in data
- Interpret aggregated values meaningfully
- Identify patterns revealed through grouping

### 8. What EDA Really Means

- Define exploratory data analysis in clear, practical terms
- Explain the goals of EDA before modeling or decisions
- Distinguish EDA from final conclusions

### 9. First Plots for Insight

- Create basic plots using matplotlib
- Choose plot types appropriate to specific questions
- Interpret plots to describe trends and patterns

### 10. Patterns and Anomalies

- Identify patterns emerging from data exploration
- Detect anomalies and unusual values
- Explain findings clearly without over-interpreting

---

## ▶️ Unit 4: Statistical Intuition for Data

This unit builds the statistical foundations needed to **analyze data correctly before modeling**, focusing on **what you are analyzing (data type), how many variables are involved, and how to reason about uncertainty**.

### Lesson 1: Data Types & “What am I analyzing?”

**Outcomes (students can…)**

- Distinguish **numerical vs categorical** variables.
- Identify whether a question is **univariate** (one variable) or **relationship-based** (two+ variables).
- Understand choosing appropriate **summary stats + visualizations** is based on data type. Get an overview of main techniques according to data type.

---

### Lesson 2: Distributions — Looking beyond single numbers

**Outcomes**

- Explain what a **distribution** represents (intuition).
- Interpret basic distribution shape using a **histogram/bar chart**.
- Describe why summary stats alone can be misleading without distribution context.

---

### Lesson 3: Mean vs Median — Choosing the right “average”

**Outcomes**

- Define **mean** and **median** with practical examples.
- Select mean vs median depending on **skew/outliers**.
- Explain how outliers can distort the mean and affect interpretation.

---

### Lesson 4: Variability & Standard Deviation (Intuition)

**Outcomes**

- Explain **variability** as “how spread out values are.”
- Interpret **standard deviation** at an intuitive level (high vs low spread).
- Compare two datasets and infer which has more variability.

---

### Lesson 5: Randomness, Noise & Why patterns can be misleading

**Outcomes**

- Define **randomness** and **noise** in real datasets.
- Recognize when a pattern may be caused by noise rather than signal.
- Explain why repeated measurements/samples may lead to different results.

---

### Lesson 6: Bivariate Thinking — Relationships between two variables

**Outcomes**

- Identify when a question requires **bivariate analysis**.
- Choose an appropriate visualization (example **scatter plot** for numeric–numeric, **box plot** for categorical–numeric).
- Describe what it means for two variables to “move together” (intuition).

---

### Lesson 7: Correlation — Pearson vs Spearman (High level)

**Outcomes**

- Define **correlation** and interpret positive vs negative correlation.
- Differentiate **Pearson** (linear) vs **Spearman** (rank/monotonic) at a high level.
- Explain when Spearman may be more appropriate than Pearson.

---

### Lesson 8: Correlation ≠ Causation

**Outcomes**

- Explain why **correlation does not imply causation**.
- Identify common pitfalls (e.g., confounders, reverse causality) conceptually.
- Propose one way to reduce wrong conclusions (e.g., check other variables, domain reasoning).

---

### Lesson 9: Multivariate Intuition — When relationships change

**Outcomes**

- Explain why adding a third variable can change an observed relationship.
- Describe “controlling for another variable” conceptually.
- Understand why we can connect multivariate thinking to **feature selection** and ML modeling decisions *(high level as it hasnt been studied yet)*

---

### Lesson 10: Probability as Uncertainty (High level)

**Outcomes**

- Explain probability as a way to describe **uncertainty**.
- Interpret probability statements in everyday terms (likelihood).
- Connect probability to variability and why results aren’t “exact.”

---

### Lesson 11: Samples vs Population — Why results vary

**Outcomes**

- Distinguish **population vs sample** intuitively.
- Explain why different samples give different results.
- Describe why we should be cautious about trusting patterns from small samples.

---

### Lesson 12: Inferential Thinking — From patterns to confidence (Very high level)

**Outcomes**

- Explain why we can’t fully trust patterns without considering uncertainty.
- Connect inferential thinking to interpreting correlations and metrics.
- Describe what it means to “generalize” from sample to population in simple terms.

---

### Lesson 13: Statistics Before ML — Bridging to modeling

**Outcomes**

- Explain why statistical intuition is critical before ML.
- Connect **variability → model error**, **probability → uncertainty**, **correlation → features**.
- Articulate readiness to move into ML task types and evaluation.

---